地址: https://icyfenix.cn/、(备用地址)http://web.archive.org/web/20220830034744/https://icyfenix.cn/

基础设施"沉淀"下去从灵活和可控的角度来说是有所倒退的. Sidecar随即诞生

通过网络进行分布式运算的八宗罪:
1. The network is reliable —— 网络是可靠的.
2. Latency is zero —— 延迟是不存在的.
3. Bandwidth is infinite —— 带宽是无限的.
4. The network is secure —— 网络是安全的.
5. Topology doesn't change —— 拓扑结构是一成不变的.
6. There is one administrator —— 总会有一个管理员.
7. Transport cost is zero —— 不必考虑传输成本.
8. The network is homogeneous —— 网络是同质化的.

远程服务调用是指位于互不重合的内存地址空间中的两个程序,在语言层面上,以同步的方式使用带宽有限的信道来传输程序控制信息

RPC协议需要解决最基本的三个问题:
1. 如何表示数据. 包括传递给方法的参数,以及方法执行后的返回值.
2. 如何传递数据. 包括异常、超时、安全、认证、授权、事务,等等.
3. 如何确定方法. 包括异构场景.

gRPC 是基于 HTTP/2 的,支持多路复用和 Header 压缩,Thrift 则直接基于传输层的 TCP 协议来实现,省去了额外应用层协议的开销

反思: 开发一个分布式系统,是不是就一定要用 RPC 呢？RPC 的三大问题源自于对本地方法调用的类比模拟,如果我们把思维从“方法调用”的约束中挣脱,那参数与结果如何表示、方法如何表示、数据如何传递这些问题都会海阔天空,拥有焕然一新的视角

REST: 表征状态转移

REST已经有一个基本清晰的结论是:面向资源编程的抽象程度通常更高

事务原子性和持久性的另一种实现思路: Shadow Paging. 但涉及隔离性与并发锁时,Shadow Paging 实现的事务并发能力就相对有限,因此在高性能的数据库中应用不多

Commit Logging 存在一个巨大的先天缺陷:所有对数据的真实修改都必须发生在事务提交以后,即日志写入了 Commit Record 之后.在此之前,即使磁盘 I/O 有足够空闲、即使某个事务修改的数据量非常庞大,占用了大量的内存缓冲区,无论有何种理由,都决不允许在事务提交之前就修改磁盘上的数据,这一点是 Commit Logging 成立的前提,却对提升数据库的性能十分不利.  ARIES 提出了“Write-Ahead Logging”的日志改进方案,所谓“提前写入”(Write-Ahead),就是允许在事务提交之前,提前写入变动数据的意思.

Write-Ahead Logging 允许 NO-FORCE,也允许 STEAL,它给出的解决办法是增加了另一种被称为 Undo Log 的日志类型,当变动数据写入磁盘前,必须先记录 Undo Log,注明修改了哪个位置的数据、从什么值改成什么值,等等.以便在事务回滚或者崩溃恢复时根据 Undo Log 对提前写入的数据变动进行擦除.Undo Log 现在一般被翻译为“回滚日志”,此前记录的用于崩溃恢复时重演数据变动的日志就相应被命名为 Redo Log,一般翻译为“重做日志”.

分布式事务中有个"理论可行"的方案是: 共享事务.  之所以强调理论可行,是因为该方案是与实际生产系统中的压力方向相悖的,一个服务集群里数据库才是压力最大而又最不容易伸缩拓展的重灾区,所以现实中只有类似ProxySQL、MaxScale这样用于对多个数据库实例做负载均衡的数据库代理(其实用 ProxySQL 代理单个数据库,再启用 Connection Multiplexing,已经接近于前面所提及的交易服务器方案了),而几乎没有反过来代理一个数据库为多个应用提供事务协调的交易服务代理.这也是说它更有可能是个伪需求的原因,如果你有充足理由让多个微服务去共享数据库,就必须找到更加站得住脚的理由来向团队解释拆分微服务的目的是什么才行.

CAP中的"A": 代表系统不间断地提供服务的能力,理解可用性要先理解与其密切相关两个指标:可靠性(Reliability)和可维护性(Serviceability).可靠性使用平均无故障时间(Mean Time Between Failure,MTBF)来度量;可维护性使用平均可修复时间(Mean Time To Repair,MTTR)来度量.可用性衡量系统可以正常使用的时间与总时间之比,其表征为:A=MTBF/(MTBF+MTTR),即可用性是由可靠性和可维护性计算得出的比例值,譬如 99.9999%可用,即代表平均年故障修复时间为32秒

http缓存分1.0的"expires"和1.1的"Cache-Control"(优先级高)

"Last-Modified"只能精确到秒级

由于HTTP1.0压缩机制导致无法计算"Content-Length"从而不能判断什么时候进行连接关闭. HTTP1.1加入了"分块传输编码"(Chuncked Transfer Encoding)的资源结束判断机制,最后以一个长度值为 0 的分块来表示资源结束

TCP 协议接到数据包丢失或损坏通知之前，可能已经收到了大量的正确数据，但是在纠正错误之前，其他的正常请求都会等待甚至被重发,这也是HTTP2在传输大文件时的缺点

CDN: 主动分发、被动回源

NAT这种模式的负载均衡存在均衡器的浏览负载限制,因为它是会直接修改请求头的. 隧道(tunnel)模式就不会有这个问题,但它会有其它的缺点

转发和代理的区别: 
- 代理: 用户不直接连接服务器，网络代理去连接。获取数据后返回给用户
- 转发: 用户直连服务器,均衡器改写数据包

如果只论网络性能，七层均衡器肯定是无论如何比不过四层均衡器的，它比四层均衡器至少多一轮 TCP 握手，有着跟 NAT 转发模式一样的带宽问题，而且通常要耗费更多的 CPU，因为可用的解析规则远比四层丰富。所以如果用七层均衡器去做下载站、视频站这种流量应用是不合适的，起码不能作为第一级均衡器。但是，如果网站的性能瓶颈并不在于网络性能，要论整个服务集群对外所体现出来的服务性能，七层均衡器就有它的用武之地了。这里面七层均衡器的底气就是来源于它工作在应用层，可以感知应用层通信的具体内容，往往能够做出更明智的决策，玩出更多的花样来
  举几个实际例子:
- 所有 CDN 可以做的缓存方面的工作（就是除去 CDN 根据物理位置就近返回这种优化链路的工作外），七层均衡器全都可以实现，譬如静态资源缓存、协议升级、安全防护、访问控制，等等。

- 七层均衡器可以实现更智能化的路由。譬如，根据 Session 路由，以实现亲和性的集群；根据 URL 路由，实现专职化服务（此时就相当于网关的职责）；甚至根据用户身份路由，实现对部分用户的特殊服务（如某些站点的贵宾服务器），等等。

- 某些安全攻击可以由七层均衡器来抵御，譬如一种常见的 DDoS 手段是 SYN Flood 攻击，即攻击者控制众多客户端，使用虚假 IP 
地址对同一目标大量发送 SYN 报文。从技术原理上看，由于四层均衡器无法感知上层协议的内容，这些 SYN 攻击都会被转发到后端的真实服务器上；而七层均衡器下这些 SYN 攻击自然在负载均衡设备上就被过滤掉，不会影响到后面服务器的正常运行。类似地，可以在七层均衡器上设定多种策略，譬如过滤特定报文，以防御如 SQL 注入等应用层面的特定攻击手段。

- 很多微服务架构的系统中，链路治理措施都需要在七层中进行，譬如服务降级、熔断、异常注入，等等。譬如，一台服务器只有出现物理层面或者系统
层面的故障，导致无法应答 TCP 请求才能被四层均衡器所感知，进而剔除出服务集群，如果一台服务器能够应答，只是一直在报 500 错，那四层均衡器对此是完全无能为力的，只能由七层均衡器来解决。

环形缓冲: 譬如一台计算机通过键盘输入，并通过 CPU 读取“HELLO WIKIPEDIA”这个长 14 字节的单词，通常需要一个至少 14 字节以上的缓冲区才行。但如果是环形缓冲结构，读取和写入就应当一起进行，在读取指针之前的位置均可以重复使用，理想情况下，只要读取指针不落后于写入指针一整圈，这个缓冲区就可以持续工作下去，能容纳无限多个新字符。否则，就必须阻塞写入操作去等待读取清空缓冲区

缓存一致性设计模式: Cache Aside、Read/Write Through、Write Behind Caching

安全方面：
- 认证（Authentication）：系统如何正确分辨出操作用户的真实身份？
- 授权（ Authorization）：系统如何控制一个用户该看到哪些数据、能操作哪些功能？
- 凭证（Credential）：系统如何保证它与用户之间的承诺是双方当时真实意图的体现，是准确、完整且不可抵赖的？
- 保密（Confidentiality）：系统如何保证敏感数据无法被包括系统管理员在内的内外部人员所窃取、滥用？
- 传输（Transport Security）：系统如何保证通过网络传输的信息无法被第三方窃听、篡改和冒充？
- 验证（Verification）：系统如何确保提交到每项服务中的数据是合乎规则的，不会对系统稳定性、数据一致性、正确性产生风险？

WebAuthn: 抛弃了传统的密码登录方式，改为直接采用生物识别（指纹、人脸、虹膜、声纹）或者实体密钥（以 USB、蓝牙、NFC 连接的物理密钥容器）来作为身份凭证，从根本上消灭了用户输入错误产生的校验需求和防止机器人模拟产生的验证码需求等问题，甚至可以省掉表单界面，所以这个规范不关注界面该是什么样子、要不要验证码、是否要前端校验这些问题

OAuth2解决的问题:
- 密码泄漏
- 访问范围
- 授权回收

HTTP Fragment("#"): 只能在客户端通过Script来读取,而不会跟随请求被发送到后端的. 
比如"http://bookstore.icyfenix.cn/#/detail/1"中"/detail/1"就不会发送到后端  

OpenID Connect (OIDC) 和 Security Assertion Markup Language (SAML) 也是广泛应用的认证和授权协议


总结: 用户了解目前web应用技术背景以及基本的主流,无深度,了解个大概即可. "不可变基础设施"那块可以多看两遍