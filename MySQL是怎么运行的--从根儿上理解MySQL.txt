MySQL
[从根儿上理解MySQL](https://juejin.im/book/5bffcbc9f265da614b11b731)

SQL相关:
```
CREATE TABLE 表名 (列的信息) ROW_FORMAT=行格式名称;
ALTER TABLE 表名 ROW_FORMAT=行格式名称;
ALTER TABLE 表名 TABLESPACE [=] innodb_file_per_table; #把已经存在系统表空间中的表转移到独立表空间(括号可有可无)
ALTER TABLE 表名 TABLESPACE [=] innodb_system; #把已经存在独立表空间的表转移到系统表空间(括号可有可无)
ANALYZE TABLE 表名; # 手动更新统计信息(innodb_table_stats和innodb_index_stats表)
XPLAIN FORMAT=JSON [SQL]; # 查看执行计划详细信息
SHOW WARNINGS; # 当code值为1003时,Message字段展示的信息类似于查询优化器将我们的查询语句重写后的语句(被优化的SQL前面需要有EXPLAIN).
SHOW ENGINE INNODB STATUS; # 查看关于InnoDB存储引擎运行过程中的一些状态信息.
```

文件扩展名对应存储内容(没有特殊说明则默认为针对InnoDB的):
*.opt: 包含当前数据库的各种属性,比如数据库的字符集和比较规则.
*.frm: 用于描述表结构(创建视图也会有一个这个,只不过它没.idb).
*.idb: 独立表空间存储表中的数据.
*.MYI: 索引文件(MyISAM).
*.MYD: 数据文件(MyISAM).
%username%.pid: 服务器进程文件.
ibdata1: 系统表空间.
ibtmp1: 数据目录中的临时表空间.
ib_logfile{i}: 存放redo log.

配置:
```
[server]
# 创建两个大小为512M的文件作为系统表空间,`autoextend`表明这两个文件如果不够回自动扩展data2文件的大小
innodb_data_file_path=data1:512M;data2:512M:autoextend
# 刻意将表数据存储到`系统表空间`
innodb_file_per_table=0
# 缓存页大小(单位: 字节)
innodb_buffer_pool_size = 268435456
# 缓存页LRU链表的old区域在LRU链表中所占的比例(默认37)
innodb_old_blocks_pct=40
# 配置读个Buffer Pool实例
innodb_buffer_pool_instances = 2
# chunk size(默认值: 128M,单位: 字节)
innodb_buffer_pool_chunk_size=134217728
```

=============================================================================================================

如果某个客户端改变了某个系统变量在`GLOBAL`作用范围的值,并不会影响该系统变量在当前已经连接的客户端作用范围为`SESSION`的值,只会影响后续连入的客户端在作用范围为`SESSION`的值

字符集比较规则后缀含义:
后缀		英文释义				描述
_ai		accent insensitive	不区分重音
_as		accent sensitive	区分重音
_ci		case insensitive	不区分大小写
_cs		case sensitive		区分大小写
_bin	binary				以二进制方式比较

4种不同类型的行格式,分别是Compact、Redundant、Dynamic和Compressed.
语法: 
```
CREATE TABLE 表名 (列的信息) ROW_FORMAT=行格式名称; 
ALTER TABLE 表名 ROW_FORMAT=行格式名称;
```

COMPACT行格式: 
结构:  
==========================================================================
|<----------记录的额外信息---------->|<---  记录的真实数据------>|
|变长字段长度列表|NULL值列表|记录头信息|列1的值|列2的值|...|列n的值|
==========================================================================
变长字段长度列表: 
	范围: VARCHAR(M)、VARBINARY(M)、各种TEXT类型,各种BLOB类型. 如果是例如utf8这种编码的情况下(长度在1~3之间),因为存在随机性,所以CHAR类型在此时也算变长.
	存储: 所有变长字段的真实数据占用的字节长度都存放在记录的开头部位,从而形成一个变长字段长度列表,各变长字段数据占用的字节数按照列的顺序逆序存放.
	例子: c1、c2、c4列存储的内容分别为'aaaa'、'bbb'、'd',且字符编码为ASCII,那么他们的变长字段长度列表用十六进制表示就是'010204'. 需要注意的是,字段长度的表示
	      不一定是一个字节,像此时内容占用的字节数比较小用一个字节就够了(这里说的是单个字段. 实际上它是有一套计算规则,大体上就是根据定义的字段字符类型
	      最大长度和实际长度来判断).
	注意: 值为 NULL 的列的长度是不存储的. 
NULL值列表:
	范围: 允许存储NULL的列.
	存储: 每个允许存储NULL的列对应一个bit位,bit位按照列的顺序逆序排列,bit位为1表示该列值为NULL,否则表示值不为NULL,并且不满一个字节时高位补0.
	注意: 值为非NULL的列是不存储的

记录头信息:
    存储: 由固定的5个字节组成(40个bit位).  [含义看图](https://i.loli.net/2019/12/19/GAT423rh78YE1Dq.png)
    介绍:
===========================================================================================================
名称				大小(单位:bit)		描述
预留位1			1					没有使用
预留位2			1					没有使用
delete_mask		1					标记该记录是否被删除
min_rec_mask	1					B+树的每层非叶子节点中的最小记录都会添加该标记
n_owned			4					表示当前记录拥有的记录数(后面有讲)
heap_no			13					表示当前记录在记录堆的位置信息(0、1位置被特殊最大、最小值占用)
record_type		3					表示当前记录的类型,0表示普通记录,1表示B+树非叶子节点记录,2表示最小记录,3表示最大记录
next_record		16					表示下一条记录的相对位置(是按照主键值从小到大排序后的下一条记录)
===========================================================================================================
n_owned: 代表以当前记录结尾的这个分组中共有几条记录.
   说明: [图片](https://i.loli.net/2020/01/07/aNvQYmh3xprbj4Z.png)
         InnoDB对数据页中的每个组中的记录条数有规定,对于最小记录所在的分组只能有1条记录,最大记录所在的分组拥有的记录条数只能
         在1~8条之间,剩下的分组中记录的条数范围只能在是4~8条之间. 

记录的真实数据:
    存储: 除了我们自己创建的列数据之外,MySQL会为每个记录默认的添加一些列(也称为隐藏列).
===========================================================================================================
列名				是否必须		占用空间		描述
DB_ROW_ID		否			6字节		行ID,唯一标识一条记录
DB_TRX_ID		是			6字节		事务ID
DB_ROLL_PTR		是			7字节		回滚指针
===========================================================================================================
说明: DB_ROW_ID是在没有主键、没有Unique键的情况下添加的.
delete_mask: 删除的记录只是打一个删除标记而已,所有被删除掉的记录都会组成一个所谓的垃圾链表,在这个链表中的记录占用的空间称之为所谓的可重用空间,
				之后如果有新记录插入到表中的话,可能把这些被删除的记录占用的存储空间覆盖掉
	   提示: 当数据页中存在多条被删除掉的记录时,这些记录的next_record属性将会把这些被删除掉的记录组成一个垃圾链表,以备之后重用这部分存储空间


Redundant行格式: 不介绍,[看原文](https://juejin.im/book/5bffcbc9f265da614b11b731/section/5bffda656fb9a049b13deba8)

Dynamic行格式: 与'Compact行格式'不同的是'行溢出'数据时会在记录的真实数据处直接存储其它页面的地址,不会记录字段真实数据的前768个字节.

Compressed行格式: 采用压缩压缩算法对页面进行压缩,以节省空间.

页: 一个页一般是16KB(并且一个页中至少存放两行记录),当记录中的数据太多,当前页放不下的时候,会把多余的数据存储到其他页中,这种现象称为行溢出.


------------------------------------------------------------------------------------------------------------------
数据页结构:
==========================================================================================
名称					中文名				占用空间大小		简单描述
File Header			文件头部				38字节			页的一些通用信息
Page Header			页面头部				56字节			数据页专有的一些信息
Infimum + Supremum	最小记录和最大记录	26字节			两个虚拟的行记录
User Records		用户记录				不确定			实际存储的行记录内容
Free Space			空闲空间				不确定			页中尚未使用的空间
Page Directory		页面目录				不确定			页中的某些记录的相对位置
File Trailer		文件尾部				8字节			校验页是否完整
==========================================================================================
heap_no: 表示当前记录在本页中的位置,从2开始. 
   提示: 0和1两个伪记录一个代表最小记录,一个代表最大记录(单词Infimum和Supremum的二进制体现),并且它们存在'Infimum + Supremum'空间中,并不和UserRecords存一起.

File Trailer: 用于判断是否将内存中的数据完整同步到磁盘.
  前4个字节代表页的校验和: 这个部分是和File Header中的校验和相对应的.每当一个页面在内存中修改了,在同步之前就要把它的校验和算出来,因为File Header
在页面的前边,所以校验和会被首先同步到磁盘,当完全写完时,校验和也会被写到页的尾部,如果完全同步成功,则页的首部和尾部的校验和应该是一致的.如果写了一半
儿断电了,那么在File Header中的校验和就代表着已经修改过的页,而在File Trailer中的校验和代表着原先的页,二者不同则意味着同步中间出了错.
  后4个字节代表页面被最后修改时对应的日志序列位置(LSN): 这个部分也是为了校验页的完整性的.   

Page Header: 
介绍: 用来存放一个数据页存储的记录的状态信息,总共56个字节.
============================================================================================================
名称							占用空间大小			描述
PAGE_N_DIR_SLOTS			2字节				在页目录中的槽数量			
PAGE_HEAP_TOP				2字节				还未使用的空间最小地址,也就是说从该地址之后就是Free Space			
PAGE_N_HEAP					2字节				本页中的记录的数量(包括最小和最大记录以及标记为删除的记录)			
PAGE_FREE					2字节		        第一个已经标记为删除的记录地址(各个已删除的记录通过next_record也会组成一个单链表,
																				这个单链表中的记录可以被重新利用)
PAGE_GARBAGE				2字节				已删除记录占用的字节数			
PAGE_LAST_INSERT			2字节				最后插入记录的位置			
PAGE_DIRECTION				2字节				记录插入的方向			
PAGE_N_DIRECTION			2字节				一个方向连续插入的记录数量			
PAGE_N_RECS					2字节				该页中记录的数量(不包括最小和最大记录以及被标记为删除的记录)			
PAGE_MAX_TRX_ID				8字节				修改当前页的最大事务ID,该值仅在二级索引中定义			
PAGE_LEVEL					2字节				当前页在B+树中所处的层级			
PAGE_INDEX_ID				8字节				索引ID,表示当前页属于哪个索引			
PAGE_BTR_SEG_LEAF			10字节				B+树叶子段的头部信息,仅在B+树的Root(根)页定义	
PAGE_BTR_SEG_TOP			10字节				B+树非叶子段的头部信息,仅在B+树的Root(根)页定义
============================================================================================================
PAGE_DIRECTION: 假如新插入的一条记录的主键值比上一条记录的主键值大,我们说这条记录的插入方向是右边,反之则是左边.
					用来表示最后一条记录插入方向的状态就是PAGE_DIRECTION.
PAGE_N_DIRECTION: 假设连续几次插入新记录的方向都是一致的,InnoDB会把沿着同一个方向插入记录的条数记下来,这个条数就用PAGE_N_DIRECTION这个状态表示.
					当然,如果最后一条记录的插入方向改变了的话,这个状态的值会被清零重新统计

PAGE_BTR_SEG_LEAF和PAGE_BTR_SEG_TOP: 它们两个都对应一个结构(后面会讲),这两个字段是用来定位'段'对应的'INODE Entry'的.

File Header:
介绍: 用来描述各种页的通用信息.
============================================================================================================
名称									占用空间大小		描述
FIL_PAGE_SPACE_OR_CHKSUM			4字节			页的校验和(checksum值)
FIL_PAGE_OFFSET						4字节			页号
FIL_PAGE_PREV						4字节			上一个页的页号
FIL_PAGE_NEXT						4字节			下一个页的页号
FIL_PAGE_LSN						8字节			页面被最后修改时对应的日志序列位置(英文名是:Log Sequence Number)
FIL_PAGE_TYPE						2字节			该页的类型
FIL_PAGE_FILE_FLUSH_LSN				8字节			仅在系统表空间的一个页中定义,代表文件至少被刷新到了对应的LSN值
FIL_PAGE_ARCH_LOG_NO_OR_SPACE_ID	4字节			页属于哪个表空间
============================================================================================================
FIL_PAGE_SPACE_OR_CHKSUM: 这个代表当前页面的校验和(checksum). 对于一个很长很长的字节串来说,会通过某种算法来计算一个比较短的值来代表这
个很长的字节串,这个比较短的值就称为校验和. 这样在比较两个很长的字节串之前先比较这两个长字节串的校验和,如果校验和都不一样两个长字节串肯定是不同的,
所以省去了直接比较两个比较长的字节串的时间损耗.

FIL_PAGE_OFFSET: 每一个页都有一个单独的页号,就跟你的身份证号码一样,InnoDB通过页号来可以唯一定位一个页

FIL_PAGE_TYPE: InnoDB为了不同的目的而把页分为不同的类型.
============================================================================================================
类型名称					十六进制		描述
FIL_PAGE_TYPE_ALLOCATED	0x0000		最新分配,还没使用
FIL_PAGE_UNDO_LOG		0x0002		Undo日志页
FIL_PAGE_INODE			0x0003		段信息节点
FIL_PAGE_IBUF_FREE_LIST	0x0004		Insert Buffer空闲列表
FIL_PAGE_IBUF_BITMAP	0x0005		Insert Buffer位图
FIL_PAGE_TYPE_SYS		0x0006		系统页
FIL_PAGE_TYPE_TRX_SYS	0x0007		事务系统数据
FIL_PAGE_TYPE_FSP_HDR	0x0008		表空间头部信息
FIL_PAGE_TYPE_XDES		0x0009		扩展描述页
FIL_PAGE_TYPE_BLOB		0x000A		溢出页
FIL_PAGE_INDEX			0x45BF		索引页,也就是我们所说的数据页
============================================================================================================
FIL_PAGE_PREV和FIL_PAGE_NEXT: 用于关联数据. 并不是所有类型的页都有这个属性(当然,'数据页'是有的,而且主要还是用于'B+树').


------------------------------------------------------------------------------------------------------------
页分裂: 下一个数据页中用户记录的主键值必须大于上一个页中用户记录的主键值

目录项记录的含义.

聚簇索引: 
1. 使用记录主键值的大小进行记录和页的排序(包括目录项记录的页).
2. B+树的叶子节点存储的是完整的用户记录.
在InnoDB存储引擎中,聚簇索引就是数据的存储方式(所有的用户记录都存储在了叶子节点),也就是所谓的索引即数据,数据即索引

字符串比较规则: 从前往后比,一旦能到了能分出大小的字符(不一样的字符)就能得出哪个更大了,不需要再比较后面的.
	     说明: 这样的比较规则就能够天然的支持'匹配列前缀'了.
     索引优化: 在创建字符串的索引时最好设置只匹配前N个字符作为创建索引、比较字符串的依据(我们管这叫'索引列前缀'). 这样能够减少页空间以及比较时间. 如:
```
CREATE TABLE person_info(
    name VARCHAR(100) NOT NULL,
    birthday DATE NOT NULL,
    phone_number CHAR(11) NOT NULL,
    country varchar(100) NOT NULL,
    KEY idx_name_birthday_phone_number (name(10), birthday, phone_number)
);    
```
说明: name(10)就表示在建立的B+树索引中只保留记录的前10个字符的编码,这种只索引字符串值的前缀的策略是我们非常鼓励的,尤其是在字符串类型能存储的字符比较多的时候.

索引列前缀对排序的影响: 无法支持排序....比如:
```
SELECT * FROM person_info ORDER BY name LIMIT 10;
```
说明: 因为只存了前10个字符,所以无法进行具体的排序了.


-------------------------------------------------------------------------------------------------------------
数据目录:
介绍: MySQL服务器程序在启动时会到文件系统的某个目录下加载一些文件,之后在运行过程中产生的数据也都会存储到这个目录下的某些
	  文件中,这个目录就称为'数据目录'.

InnoDB表空间: 
系统表空间(system tablespace): 存放表数据,可自动扩展,默认文件名为'ibdata1',只有一份. 从MySQL5.5.7到MySQL5.6.6之间的各个版本中,
							   我们表中的数据都会被默认存储到这里.               

独立表空间(file-per-table tablespace):  MySQL5.6.6以及之后的版本默认使用这个.

配置: 
```
[server]
# 0表示使用系统表空间.  1表示使用独立表空间
innodb_file_per_table=0 
```

语法:
```
# '='号可有可无
# 已经存在系统表空间中的表转移到独立表空间
ALTER TABLE 表名 TABLESPACE [=] innodb_file_per_table;

# 已经存在独立表空间的表转移到系统表空间
ALTER TABLE 表名 TABLESPACE [=] innodb_system;
```

其他类型的表空间: 通用表空间(general tablespace)、undo表空间(undo tablespace)、临时表空间(temporary tablespace)等等...
=====================================================================================================================

=====================================================================================================================
MyISAM存储表数据: 它和InnoDB不一样,索引都是二级索引,所以数据和索引是分开存储的,而且没有表空间的说法.  
每个表由三个文件组成: 
```
test.frm
test.MYD
test.MYI
```
=====================================================================================================================


系统数据库:
mysql: 存储了MySQL的用户账户和权限信息,一些存储过程、事件的定义信息,一些运行过程中产生的日志信息,一些帮助信息以及时区信息等

information_schema: 保存着MySQL服务器维护的所有其他数据库的信息,比如有哪些表、哪些视图、哪些触发器、哪些列、哪些索引吧啦吧啦.
					这些信息并不是真实的用户数据,而是一些描述性信息,有时候也称之为元数据

performance_schema: 保存MySQL服务器运行过程中的一些状态信息,算是对MySQL服务器的一个性能监控.包括统计最近执行了哪些语句,
					在执行过程的每个阶段都花费了多长时间,内存的使用情况等等信息.

sys: 主要是通过视图的形式把information_schema和performance_schema结合起来,让程序员可以更方便的了解MySQL服务器的一些性能信息.


-------------------------------------------------------------------------------------------------------------------
表空间里的'区':
说明: 为了方便管理,同一'表空间'中,对于16KB的页来说,连续的64个页就是一个'区'(英文名'extent'),也就是一个区默认占用1MB空间大小. 每256个区被划分成一组.
      也就是说,最多一个'区'=1MB、一个'组'=256MB

碎片区: 碎片区中的页可以用于不同的目的,比如有些页用于段A,有些页用于段B,有些页甚至哪个段都不属于.碎片区直属于表空间,并不属于任何一个段
		  段是一些零散的页面以及一些完整的区的集合.

区大体上可以分为4种类型: 空闲的区、有剩余空间的碎片区、没有剩余空间的碎片区、附属于某个段的区

存放叶子节点的区的集合就算是一个段(segment),存放非叶子节点的区的集合也算是一个段
区=64个页. 
每一个区都对应着一个XDES Entry结构,这个结构记录了对应的区的一些属性

某个段分配存储空间的策略:
1. 在刚开始向表中插入数据的时候,段是从某个碎片区以单个页面为单位来分配存储空间的.
2. 当某个段已经占用了32个碎片区页面之后(512KB),就会以完整的区为单位来分配存储空间.

区的四种状态:
===================================
状态名		含义
FREE		空闲的区
FREE_FRAG	有剩余空间的碎片区
FULL_FRAG	没有剩余空间的碎片区
FSEG		附属于某个段的区
===================================
说明: 处于FREE、FREE_FRAG以及FULL_FRAG这三种状态的区都是独立的,算是直属于表空间;而处于FSEG状态的区是附属于某个段的.

如果我们想定位表空间内的某一个位置的话,只需指定页号以及该位置在指定页号中的页内偏移量即可. 

XDES Entry(Extent Descriptor Entry): 为了方便管理这些各种状态的区,InnoDb设计了XDES Entry的结构,用来记录对应的区的一些属性.
XDES Entry结构:
Segment ID(8字节): 每一个段都有一个唯一的编号. 此处的SegmentID字段表示就是该区所在的段.当然前提是该区已经被分配给某个段了,不然的话该字段的值没啥意义
List Node(12字节): 帮助XDES Entry组成一个链表. 包括: Pre Node Page Number、Pre Node Offset、Next Node Page Number、Next Node Offset 
State(4字节): 表名区状态. FREE(空闲)、FREE_FRAG(有剩余空间)、FULL_FRAG(没有剩余空间)和FSEG(附属于某个段的区).
Page State Bitmap(16字节): 128个比特位,一个区默认64个页. 划分下就是2个比特位对应区中的一个页,第一个bit表示页是否空闲,第二个还没用.

为了解决各个段对应的XDES Entry链表数据分配不均匀问题:
原因: 因为段中数据已经占满了32个零散的页后分配完整的区,但不能获取到段对应的区的链表. 所以每个段都有它独立的(区)链表,并且可以根据段号(也就是Segment ID)
	  来建立链表,只能有多少个段就建立多少个链表. 导致资源存在浪费(有的区是完全空闲的,有的区还有一些页面可以用,有的区已经没有空闲页面可以用了). 所以有必要
	  细分,设计InnoDB的大叔们为每个段中的区对应的XDES Entry结构建立了三个链表(基节点信息在INODE Entry中).
每一个索引都对应两个段,每个段都会维护上述的3个链表: FREE链表、NOT_FULL链表、FULL链表
假如一个表有两个索引,则有15个链表: 4个段*3个链表+直属于表空间的3个链表
 
List Base Node(链表基节点结构): 
说明: 包含了(上面的)链表的头节点和尾节点的指针以及这个链表中包含了多少节点的信息. INODE Entry中根据它记录的信息来找各种区.
结构: 
List Length表明该链表一共有多少节点.
First Node Page Number和First Node Offset表明该链表的头节点在表空间中的位置(XDES Entry链表头节点的指针).
Last Node Page Number和Last Node Offset表明该链表的尾节点在表空间中的位置(XDES Entry链表尾节点的指针).

链表小结: 
综上所述,表空间是由若干个区组成的,每个区都对应一个XDES Entry的结构,
直属于表空间的区对应的XDES Entry结构可以分成FREE、FREE_FRAG和FULL_FRAG这3个链表;
每个段可以附属若干个区,每个段中的区对应的XDES Entry结构可以分成FREE、NOT_FULL和FULL这3个链表.
每个链表都对应一个List Base Node的结构,这个结构里记录了链表的头、尾节点的位置以及该链表中包含的节点数.
正是因为这些链表的存在,管理这些区才变成了一件so easy的事情.


INODE Entry: 和每个区都有对应是XDES Entry来记录这个区中的属性一样,INODE Entry结构来记录段中的属性.
INODE Entry结构:
Segment ID: INODE Entry结构对应的段的编号(ID).
NOT_FULL_N_USED: 在NOT_FULL链表中已经使用了多少个页面.下次从NOT_FULL链表分配空闲页面时可以直接根据这个字段的值定位到.
					而不用从链表中的第一个页面开始遍历着寻找空闲页面.
3个List Base Node: 分别为段的FREE链表、NOT_FULL链表、FULL链表定义了List Base Node,这样我们想查找某个段的某个链表的头节点和尾节点的时候,
					就可以直接到这个部分找到对应链表的List Base Node.
Magic Number: 这个值是用来标记这个INODE Entry是否已经被初始化了(初始化的意思就是把各个字段的值都填进去了).如果这个数字是值的97937874,
				表明该INODE Entry已经初始化,否则没有被初始化.
Fragment Array Entry: 段是一些零散页面和一些完整的区的集合,每个Fragment Array Entry结构都对应着一个零散的页面,这个结构一共4个字节,
					   表示一个零散页面的页号


FIL_PAGE_TYPE_FSP_HDR类型的页: 第一个组的第一个页面,也是表空间的第一个页面,页号为0. 存储了表空间的一些整体属性以及第一个组内256个区的对应的XDES Entry结构.
结构:
File Header(38字节): 页的一些通用信息.
File Space Header(112字节): 表空间的一些整体属性信息.
XDES Entry(10240字节): 存储本组256个区对应的属性信息.
Empty Space(5986字节): 用于页结构的填充,没啥实际意义.
File Trailer(8字节): 校验页是否完整.

File Space Header结构:
========================================================================================================
名称											占用空间大小		描述
Space ID									4字节			表空间的ID
Not Used									4字节			这4个字节未被使用,可以忽略
Size										4字节			当前表空间占有的页面数
FREE Limit									4字节			尚未被初始化的最小页号,大于或等于这个页号的区对应的XDES Entry结构都没有被加入FREE链表
Space Flags									4字节			表空间的一些占用存储空间比较小的属性
FRAG_N_USED									4字节			FREE_FRAG链表中已使用的页面数量
List Base Node for FREE List				16字节			FREE链表的基节点
List Base Node for FREE_FRAG List			16字节			FREE_FRAG链表的基节点
List Base Node for FULL_FRAG List			16字节			FULL_FRAG链表的基节点
Next Unused Segment ID						8字节			当前表空间中下一个未使用的 Segment ID
List Base Node for SEG_INODES_FULL List		16字节			SEG_INODES_FULL链表的基节点
List Base Node for SEG_INODES_FREE List		16字节			SEG_INODES_FREE链表的基节点
========================================================================================================
介绍:
FREE Limit: 在该字段表示的页号之前的区都被初始化了,之后的区尚未被初始化.
Next Unused Segment ID: 为了方便新建索引时选择'唯一Segment ID'.
Space Flags: 4个字节,32个比特位,存了些表空间的属性. 不展开来了解,可以看
				[原文](https://juejin.im/book/5bffcbc9f265da614b11b731/section/5c061ac46fb9a049e66003f2)
				、[截图](https://i.loli.net/2020/01/10/xabV9lKcYg3Qzkq.png).
List Base Node for SEG_INODES_FULL List和List Base Node for SEG_INODES_FREE List: 每个段对应的INODE 
  Entry结构会集中存放到一个类型为INODE的页中,如果表空间中的段特别多,则会有多个INODE Entry结构,可能一个页放不下,这些INODE类型的页会组成两种列表:
  1. SEG_INODES_FULL链表: 该链表中的INODE类型的页面都已经被INODE Entry结构填充满了,没空闲空间存放额外的INODE Entry了.
  2. SEG_INODES_FREE链表: 该链表中的INODE类型的页面仍有空闲空间来存放INODE Entry结构.


XDES Entry部分: 为什么只能存放256个,因为XDES Entry结构大小是40字节,但一个页面的大小有限,只能存放256个XDES Entry结构.


FIL_PAGE_TYPE_XDES类型页: 除去第一个分组以外的每个分组的第一个页面的类型定义为'XDES'(简写). 
						 全称'extent descriptor',用来登记本组256个区的属性.
结构: 少了File Space Header,也就是除了少了记录表空间整体属性的部分之外,其余的部分是一样的.


FIL_PAGE_IBUF_BITMAP类型页: 每个分组的第二个页面的类型都是IBUF_BITMAP,这种类型的页里边记录了一些有关Change Buffer的东西.
		[Change Buffer存根_TODO](https://dev.mysql.com/doc/refman/5.7/en/innodb-change-buffer.html)


FIL_PAGE_INODE类型页: 第一个分组的第三个页面的类型是INODE. 每个索引定义了两个段,而且为某些特殊功能定义了些特殊的段. 为了方便管理,
					  为每个段设计了一个INODE Entry结构,这个结构中记录了关于这个段的相关属性.这个INODE类型的页就是为了存储
					  INODE Entry结构而存在的(在表空间的第一个'组'里).
结构:
File Header(38字节)
List Node for INODE Page List(12字节): 存储上一个INODE页面和下一个INODE页面的指针
INODE Entry(16320字节)
Empty Space(6字节): 用于页结构的填充,没啥实际意义
File Trailer(8字节)

INODE Entry: 每个INODE Entry结构占用192字节,一个页面里可以存储85个这样的结构.
List Node for INODE Page List: 因为一个表空间中可能存在超过85个段,所以可能一个INODE类型的页面不足以存储所有的段对应的INODE 
							 	Entry结构,所以就需要额外的INODE类型的页面来存储这些结构.
		其它: 它的基节点是存放在FSP_HDR页的File Space Header里的,也就是说基节点是固定的,方便.

创建段(索引)时的INODE Entry分配也是有套流程的.


Segment Header:
段是一个逻辑上的概念. INODE Entry来记录段的属性.
INDEX类型的页有一个Page Header中有PAGE_BTR_SEG_LEAF和PAGE_BTR_SEG_TOP两个字段,这里再介绍下:
PAGE_BTR_SEG_LEAF(10字节): B+树叶子段的头部信息. 仅在B+树的根页定义!!!
PAGE_BTR_SEG_TOP(10字节): B+树非叶子段的头部信息. 仅在B+树的根页定义!!!
它们两个其实都对应着一个叫Segment Header的结构:
Space ID of the INODE Entry: INODE Entry结构所在的表空间ID
Page Number of the INODE Entry: INODE Entry结构所在的页面页号
Byte Offset of the INODE Entry: INODE Entry结构在该页面中的偏移量
PAGE_BTR_SEG_LEAF记录着叶子节点段对应的INODE Entry结构的地址是哪个表空间的哪个页面的哪个偏移量,PAGE_BTR_SEG_TOP记录着非叶子节点段对应的
INODE Entry结构的地址是哪个表空间的哪个页面的哪个偏移量. 这样子索引和其(段)对应的关系就建立起来了. 还有一点就是因为一个索引值对应两个段,所以只需要
在索引的根页面中记录着两个结构.


------------------------------------------------------------------------------------------------------------------------
系统表空间:
表空间 ID(Space ID)是0.
系统表空间与独立表空间的一个非常明显的不同之处就是在表空间开头有许多记录整个系统属性的页面.

系统表空间和独立表空间的第1个区的前三个页面的类型都是一致的,其它不同的页面如下:
===========================================================================
页号		页面类型			英文描述					描述
3		SYS				Insert Buffer Header	存储Insert Buffer的头部信息
4		INDEX			Insert Buffer Root		存储Insert Buffer的根页面
5		TRX_SYS			Transction System		事务系统的相关信息
6		SYS				First Rollback Segment	第一个回滚段的页面
7		SYS				Data Dictionary Header	数据字典头部信息
============================================================================

系统表空间的extent 1和extent 2这两个区,也就是页号从64~191这128个页面被称为Doublewrite buffer,也就是双写缓冲区.
[Doublewrite Buffer存根_TODO](https://dev.mysql.com/doc/refman/5.7/en/innodb-doublewrite-buffer.html)

4个特殊表分别为: SYS_TABLES、SYS_COLUMNS、SYS_INDEXES、SYS_FIELDS. 它们记录了所有表的表信息(包括它们自己).

页号为7的页面,类型为SYS,记录了Data Dictionary Header,也就是数据字典的头部信息. 它记录了4个特殊表(表示表的表)的聚簇索引和二级索引对应的
B+树位置. 除了这4个表的5个索引的根页面信息外,这个页号为7的页面还记录了整个InnoDB存储引擎的一些全局属性:

Data Dictionary Header页的Data Dictionary Header字段的信息:
Max Row ID: 记录下一次DB_ROW_ID(InnoDB为我们在没ID Key、UNIQUE索引的情况下自动创建的列)的值. 全局共享、自增.
Max Table ID: 所有表都对应一个ID.
Max Index ID: 所有索引都对应一个ID.
Max Space ID: 所有表空间都对应一个ID.
Root of SYS_TABLES clust index: SYS_TABLES表聚簇索引的根页面的页号
Root of SYS_TABLE_IDS sec index: SYS_TABLES表为ID列建立的二级索引的根页面的页号
Root of SYS_COLUMNS clust index: SYS_COLUMNS表聚簇索引的根页面的页号
Root of SYS_INDEXES clust index: SYS_INDEXES表聚簇索引的根页面的页号
Root of SYS_FIELDS clust index: SYS_FIELDS表聚簇索引的根页面的页号

注意: 在information_schema数据库中的这些以INNODB_SYS开头的表并不是真正的内部系统表(内部系统表就是我们上边唠叨的以SYS开头的那些表),
	  而是在存储引擎启动时读取这些以SYS开头的系统表,然后填充到这些以INNODB_SYS开头的表中.以INNODB_SYS开头的表和以SYS开头的表中的字段并不完全一样.


------------------------------------------------------------------------------------------------------------------------
单表访问方法

Block Nested-Loop Join(基于块的嵌套连接)算法: 就是执行连接查询前申请的一块固定大小的内存(join buffer),先把若干条驱动表结果集中的记录装在这个
      join buffer中,然后开始扫描被驱动表,每一条被驱动表的记录一次性和join buffer中的多条驱动表记录做匹配. 这样就可以避免被驱动表的O(N^2)次查询了.
设置: join_buffer_size(默认为262144byte,也就是256KB).

基于成本的优化: 
组成: 
读取一个页面: 1.0
读取以及检测一条记录是否符合条件: 0.2

MySQL为每个表维护了一系列的统计信息: 聚簇索引占用的页面数、该表中的记录数

计算索引的成本:
I/O成本: 回表
CPU成本: 读取二级索引记录的成本 + 读取并检测回表后聚簇索引记录的成本(检测除二级索引条件外的搜索条件)

MySQL把通过直接访问索引对应的B+树来计算某个范围区间对应的索引记录条数的方式称之为index dive

像会为每个表维护一份统计数据一样,MYSQL也会为表中的每一个索引维护一份统计数据:
====================================================================================
属性名			描述
Table			索引所属表的名称.
Non_unique		索引列的值是否是唯一的,聚簇索引和唯一二级索引的该列值为0,普通二级索引该列值为1.
Key_name		索引的名称.
Seq_in_index	索引列在索引中的位置,从1开始计数.比如对于联合索引idx_key_part,来说,key_part1、key_part2和key_part3对应的位置分别是1、2、3.
Column_name		索引列的名称.
Collation		索引列中的值是按照何种排序方式存放的,值为A时代表升序存放,为NULL时代表降序存放.
Cardinality		索引列中不重复值的数量.
Sub_part		对于存储字符串或者字节串的列来说,有时候我们只想对这些串的前n个字符或字节建立索引,这个属性表示的就是那个n值.如果对完整的列
					建立索引的话,该属性的值就是NULL.
Packed			索引列如何被压缩,NULL值表示未被压缩.这个属性我们暂时不了解,可以先忽略掉.
Null			该索引列是否允许存储NULL值.
Index_type		使用索引的类型,我们最常见的就是BTREE,其实也就是B+树索引.
Comment			索引列注释信息.
Index_comment	索引注释信息.
====================================================================================

IN语句中的参数个数大于或等于系统变量eq_range_index_dive_limit的值的话,就不会使用index dive的方式计算各个单点区间对应的索引记录条数,
	而是使用索引统计数据,这里所指的索引统计数据指的是这两个值:
1. 使用SHOW TABLE STATUS展示出的Rows值,也就是一个表中有多少条记录.
2. 使用SHOW INDEX语句展示出的'Cardinality'属性.
计算一个值重复次数: 一个值的重复次数 ≈ Rows ÷ Cardinality;
假设这个值为10(条),再带入`SELECT * FROM single_table WHERE  key1 IN('aa1','aa2','aa3',......,'zzz')`. 假设IN语句中有2w个参数的话,就
  直接使用统计数据来估算这些参数需要单点区间对应的记录条数了,每个参数大约对应10条记录,所以总共需要回表的记录数: 2w * 10 = 20w.

MYSQL在进行两表连接成本分析时的连接顺序并不一定会按照执行的SQL连接顺序一样进行分析,而是同时会将驱动表、被驱动表交叉分析.
如果原本的被驱动表作为驱动表时的总执行成本更少的话,则可能它会作为驱动表,另一个作为被驱动表.

连接成本计算: 连接查询总成本 = 单次访问驱动表的成本 + 驱动表扇出数 x 单次访问被驱动表的成本;
优化重点: 尽量减少驱动表的扇出、对被驱动表的访问成本尽量低. 
建议: 尽量在被驱动表的连接列上建立索引,这样就可以使用ref访问方法来降低访问被驱动表的成本了.

server层的一些操作对应的'成本常数':
==========================================================================================
本常数名称						默认值		描述
disk_temptable_create_cost		40.0	创建基于磁盘的临时表的成本,如果增大这个值的话会让优化器尽量少的创建基于磁盘的临时表.
disk_temptable_row_cost			1.0		向基于磁盘的临时表写入或读取一条记录的成本,如果增大这个值的话会让优化器尽量少的创建基于磁盘的临时表.
key_compare_cost				0.1		两条记录做比较操作的成本,多用在排序操作上,如果增大这个值的话会提升filesort的成本,让优化器可能更倾
											向于使用索引完成排序而不是filesort.
memory_temptable_create_cost	2.0		创建基于内存的临时表的成本,如果增大这个值的话会让优化器尽量少的创建基于内存的临时表.
memory_temptable_row_cost		0.2		向基于内存的临时表写入或读取一条记录的成本,如果增大这个值的话会让优化器尽量少的创建基于内存的临时表.
row_evaluate_cost				0.2		这个就是我们之前一直使用的检测一条记录是否符合搜索条件的成本,增大这个值可能让优化器更倾向于使用
											索引而不是直接全表扫描.
==========================================================================================
说明:
  MySQL在执行诸如DISTINCT查询、分组查询、Union查询以及某些特殊条件下的排序查询都可能在内部先创建一个临时表,使用这个临时表来辅助完成查询(比如对于DISTINCT查询可
以建一个带有UNIQUE索引的临时表,直接把需要去重的记录插入到这个临时表中,插入完成之后的记录就是结果集了).在数据量大的情况下可能创建基于磁盘的临时表,也就是为该临
时表使用MyISAM、InnoDB等存储引擎,在数据量不大时可能创建基于内存的临时表,也就是使用Memory存储引擎. 创建临时表和对这个临时表进行写入和读取的操作代价挺高.

更新server端某个成本常数值:
```
-- cost_value=NULL表示用默认值
UPDATE mysql.server_cost SET cost_value = 0.4 WHERE cost_name = 'row_evaluate_cost';
FLUSH OPTIMIZER_COSTS;
```

engine层比server层多两列: 
engine_name: 成本常数适用的存储引擎名称.如果该值为default,意味着对应的成本常数适用于所有的存储引擎
device_type: 存储引擎使用的设备类型,这主要是为了区分常规的机械硬盘和固态硬盘. 'MySQL 5.7.21'没有对其作区分,默认为0.
=========================================================================================================================================
成本常数名称				默认值		描述
io_block_read_cost		1.0			从磁盘上读取一个块对应的成本.请注意我使用的是块,而不是页这个词儿.对于InnoDB存储引擎来说,一个页就是一个块,
									不过对于MyISAM存储引擎来说,默认是以4096字节作为一个块的.增大这个值会加重I/O成本,可能让优化器更倾向于选择使用
									索引执行查询而不是执行全表扫描.
memory_block_read_cost	1.0			与上一个参数类似,只不过衡量的是从内存中读取一个块对应的成本.
=========================================================================================================================================


innodb_table_stats表各列:
============================================================================
字段名						描述
database_name				数据库名
table_name					表名
last_update					本条记录最后更新时间
n_rows						表中记录的条数
clustered_index_size		表的聚簇索引占用的页面数量
sum_of_other_index_sizes	表的其他索引占用的页面数量
============================================================================
n_rows统计规则: 按照一定算法(并不是纯粹随机的)选取几个叶子节点页面,计算每个页面中主键值记录数量,然后计算平均一个页面中主键值的记录数量
				 乘以全部叶子节点的数量就算是该表的n_rows值.
		  说明: 'innodb_stats_persistent_sample_pages'是用来控制使用永久性的统计数据时,计算统计数据时的采样的页面数量(越大越精确,越耗时. 默认20).
		  		可以通过创建表时指定'STATS_SAMPLE_PAGES'属性来指明.
```
CREATE TABLE 表名 (...) Engine=InnoDB, STATS_SAMPLE_PAGES = 具体的采样页面数量;
OR
ALTER TABLE 表名 Engine=InnoDB, STATS_SAMPLE_PAGES = 具体的采样页面数量;
```

innodb_index_stats表各列:
============================================================================
字段名				描述
database_name		数据库名
table_name			表名
index_name			索引名
last_update			本条记录最后更新时间
stat_name			统计项的名称
stat_value			对应的统计项的值
sample_size			为生成统计数据而采样的页面数量
stat_description	对应的统计项的描述
============================================================================
stat_name:
	n_leaf_pages: 表示该索引的叶子节点占用多少页面.
	size: 表示该索引共占用多少页面.
	n_diff_pfxNN: 表示对应的索引列不重复的值有多少.
说明: 'n_diff_pfxNN'中的'NN'是可被替换为01、02、03的数字.
拿idx_key_part来说,具体含义:
n_diff_pfx01表示的是统计key_part1这单单一个列不重复的值有多少.
n_diff_pfx02表示的是统计key_part1、key_part2这两个列组合起来不重复的值有多少.
n_diff_pfx03表示的是统计key_part1、key_part2、key_part3这三个列组合起来不重复的值有多少.
n_diff_pfx04表示的是统计key_part1、key_part2、key_part3、id这四个列组合起来不重复的值有多少(注意下这个).

注意: 像idx_key2这种本就是唯一索引来说,它只有n_diff_pfx01一个统计项.

sample_size: 在计算某些索引列中包含多少不重复值时,需要对一些叶子节点页面进行采样,sample_size列就表明了采样的页面数量是多少.

定期更新统计数据:
开启innodb_stats_auto_recalc(默认ON): 当表发生变动的记录数量超过了表大小的10%,则会异步重新计算、统计数据.  
手动调用ANALYZE TABLE语句来更新统计信息(同步的): 
```
ANALYZE TABLE single_table;
```

还有一点就是'innodb_index_stats'、'innodb_table_stats'两个表都是普通表,可以自己手动改数据的.

'索引列不重复值的数量'这个统计数据对于MySQL查询优化器十分重要,因为通过它可以计算出索引列中平均一个值重复多少行,它的应用场景主要
有两个:
1. 单表查询中单点区间太多,比如: ` SELECT * FROM tbl_name WHERE key IN ('xx1', 'xx2', ..., 'xxn'); `
   当`IN`里的参数数量过多时,采用'index dive'的方式直接访问B+树索引去统计每个单点区间对应的记录的数量就太耗费性能了,
   所以直接依赖统计数据中的平均一个值重复多少行来计算单点区间对应的记录数量.
2. 连接查询时,如果有涉及两个表的等值匹配连接条件,该连接条件对应的被驱动表中的列又拥有索引时,则可以使用ref访问方法来对被驱动表进行查询,比如:
   `SELECT * FROM t1 JOIN t2 ON t1.column = t2.key WHERE ...;`
   在真正执行对t2表的查询前,t1.comumn的值是不确定的,所以我们也不能通过index dive的方式直接访问B+树索引去统计每个单点区间对应的记录的数量,
   所以也只能依赖统计数据中的平均一个值重复多少行来计算单点区间对应的记录数量.

innodb_stats_method:
介绍: 用于在计算某个索引列不重复值的数量时如何对待NULL值.
nulls_equal:认为所有NULL值都是相等的.这个值也是innodb_stats_method的默认值.
  	    说明: 如果某个索引列中NULL值特别多的话,这种统计方式会让优化器认为某个列中平均一个值重复次数特别多,所以倾向于不使用索引进行访问(成本太高).
nulls_unequal:认为所有NULL值都是不相等的.
		说明: 与上面相反.
nulls_ignored:直接把NULL值忽略掉.


------------------------------------------------------------------------------------------------
基于规则的优化:

在外连接查询中,指定的WHERE子句中包含被驱动表中的列不为NULL值的条件称之为空值拒绝(英文名:reject-NULL).

子查询: 
说明: MySQL把由子查询结果集组成的表称之为派生表.
标量子查询: 只返回一个单一值的子查询.
			` SELECT (SELECT m1 FROM t1 LIMIT 1); `
行子查询: 返回一条记录的子查询(需要包含多个列,只包含一个列就成了标量子查询).
		  ` SELECT * FROM t1 WHERE (m1, n1) = (SELECT m2, n2 FROM t2 LIMIT 1); `
列子查询: 查询出一个列,不过这个列的数据需要包含多条记录(只包含那一条记录就成了标量子查询).
		  ` SELECT * FROM t1 WHERE m1 IN (SELECT m2 FROM t2); `
表子查询: 查询结果既包含很多条记录,又包含很多个列.
		  ` SELECT * FROM t1 WHERE (m1, n1) IN (SELECT m2, n2 FROM t2); `

`IN`子查询的优化: 
`IN`子查询带来的问题: 
	1. 结果集太多,内存可能装不下. 		  
    2. 对于外层查询来说,如果子查询的结果集太多,那就意味着IN子句中的参数特别多,这就导致:
    	2.1: 无法有效的使用索引,只能对外层查询进行全表扫描.
    	2.2: 在对外层查询执行全表扫描时,由于IN子句中的参数太多,这会导致检测一条记录是否符合和IN子句中的参数匹配花费的时间太长.

解决方案: 不直接将不相关子查询的结果集当作外层查询的参数,而是将该结果集写入一个临时表里.
*: 该临时表的列就是子查询结果集中的列.
*: 写入临时表的记录会被去重.
*: 一般情况下子查询结果集不会大的离谱,所以会为它建立基于内存的使用Memory存储引擎的临时表,而且会为该表建立哈希索引.

其它说明: 
tmp_table_size和max_heap_table_size用于配置存放子查询结果集临时表的内存大小,默认值16777216Byte(一个页的大小).
一旦超过了这个大小就会转而使用基于磁盘的存储引擎来保存结果集中的记录,索引类型也会由哈希索引转变为B+数索引.

MySQL对IN类型的子查询优化会将其转变为内连接,关联的表(此时不能说是被驱动方)为那个IN返回的临时表.
SQL: ` SELECT * FROM s1 WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = 'a'); `
转换后: ` SELECT s1.* FROM s1 INNER JOIN materialized_table ON key1 = m_val; `
说明: 'materialized_table'为假设的临时表,'m_val'为假设'materialized_table'表中对应之前的'common_field'字段.
内连接成本组合:
s1表作为驱动表时:
1. 物化子查询时需要的成本
2. 扫描s1表时的成本
3. s1表中的记录数量 × 通过m_val = xxx对materialized_table表进行单表访问的成本(我们前边说过物化表中的记录是不重复的,并且为物化表中的列建立了索引,
																			所以这个步骤显然是非常快的)
materialized_table作为驱动表时: 
1. 物化子查询时需要的成本
2. 扫描物化表时的成本
3. 物化表中的记录数量 × 通过key1 = xxx对s1表进行单表访问的成本(key1列上建立了索引,所以这个步骤非常快)

将子查询转换为semi-join:
示例SQL: ` SELECT * FROM s1 WHERE key1 IN (SELECT common_field FROM s2 WHERE key3 = 'a'); `
	模拟内连接: ` SELECT s1.* FROM s1 INNER JOIN s2 ON s1.key1 = s2.common_field WHERE s2.key3 = 'a'; `
	semi-join: ` SELECT s1.* FROM s1 SEMI JOIN s2 ON s1.key1 = s2.common_field WHERE key3 = 'a'; `
目的: 不进行物化操作直接把子查询转换未连接查询.
说明: 将s1表和s2表进行半连接的意思就是...对于s1表的某条记录来说,我们只关心在s2表中是否存在与之匹配的记录是否存在,
	  而不关心具体有多少条记录与之匹配,最终的结果集中只保留s1表的记录.
具体实现: 
  1. Table pullout(子查询中的表上拉): 子查询的查询列表处只有主键或者唯一索引列时,可以直接把子查询中的表上拉到外层查询的FROM子句中,
  									 并把子查询中的搜索条件合并到外层查询的搜索条件中.
  2. DuplicateWeedout execution strategy(重复值消除): 将子查询转换为半连接查询后,s1表中的某条记录可能在s2表中有多条匹配的记录,
  					所以该条记录可能多次被添加到最后的结果集中,为了消除重复,我们可以建立一个临时表,每当某条s1表中的记录要加入结果集时,
  					就首先把这条记录的id值加入到这个临时表里,如果添加成功,说明之前这条s1表中的记录并没有加入最终的结果集,现在把该记录
  					添加到最终的结果集;如果添加失败,说明之前这条s1表中的记录已经加入过最终的结果集,这里直接把它丢弃就好了.
  3. LooseScan execution strategy(松散扫描): 
  		示例SQL: ` SELECT * FROM s1 WHERE key3 IN (SELECT key1 FROM s2 WHERE key1 > 'a' AND key1 < 'b'); `					
  		   说明: 在子查询中,对于s2表的访问可以使用到key1列的索引,而恰好子查询的查询列表处就是key1列,这样在将该查询转换为半连接查询后,
  		   		 如果将s2作为驱动表执行查询的话,那么s2的结果集:
  		   		 ```
	 				+------+
					| key1 |
					+------+
					| aa   |
					| aa   |
					| aa   |
					| ab   |
					| ab   |
					| ac   |
					| ac   |
					| ac   |
					+------+
  		   		 ```
  		   		 只需要取第一条不重复的值到s1表中查找s1.key3 = 'aa'的记录,如果能在s1表中找到对应的记录,那么就把对应的记录加入到结果集.
  		   		 依此类推,其他值相同的二级索引记录,也只需要取第一条记录的值到s1表中找匹配的记录,这种虽然是扫描索引,但只取值相同的记录
  		   		 的第一条去做匹配操作的方式称之为松散扫描.

  4. Semi-join Materialization execution strategy(物化连接): 上面讲的物化表的连接本质上也算是一种semi-join.
  5. FirstMatch execution strategy(首次匹配): 先取一条外层查询的中的记录,然后到子查询的表中寻找符合匹配条件的记录,如果能找到一条,
  								则将该外层查询的记录放入最终的结果集并且停止查找更多匹配的记录,如果找不到则把该外层查询的记录丢弃掉;
  								然后再开始取下一条外层查询中的记录,重复上边这个过程.
适用条件: 
*: 该子查询必须是和IN语句组成的布尔表达式,并且在外层查询的WHERE或者ON子句中出现.
*: 外层查询也可以有其他的搜索条件,只不过和IN子查询的搜索条件必须使用AND连接起来.
*: 该子查询必须是一个单一的查询,不能是由若干查询由UNION连接起来的形式.
*: 该子查询不能包含GROUP BY或者HAVING语句或者聚集函数.
其它优化: 虽然上面写了很多不适用于semi-join优化的场景,但是MySQL还是有些其它手段来想办法将其优化.
      *: 对于不相关子查询来说,可以尝试把它们物化之后再参与查询.
         SQL: ` SELECT * FROM s1 WHERE key1 NOT IN (SELECT common_field FROM s2 WHERE key3 = 'a'); `
        说明: 先将子查询物化,然后再判断key1是否在物化表的结果集中可以加快查询执行的速度.
      *: 不管子查询是相关的还是不相关的,都可以把IN子查询尝试转为EXISTS子查询,其实对于任意一个IN子查询来说,都可以被转为EXISTS子查询.
	  	 通用例子: ` outer_expr IN (SELECT inner_expr FROM ... WHERE subquery_where); `         
	  	 转换结果: ` EXISTS (SELECT inner_expr FROM ... WHERE subquery_where AND outer_expr=inner_expr); `
	  	    例子:
	  	       转换前:  ` SELECT * FROM s1 WHERE key1 IN (SELECT key3 FROM s2 where s1.common_field = s2.common_field) OR key2 > 1000; `
	  	       转换后:  ` SELECT * FROM s1 WHERE EXISTS (SELECT 1 FROM s2 where s1.common_field = s2.common_field AND s2.key3 = s1.key1) `
						` OR key2 > 1000; `
注意(显得有点多余了): 
1. 相关子查询并不是一个独立的查询不能转换为物化表来执行查询.
2. 如果IN子查询不满足转换为semi-join的条件,又不能转换为物化表或者转换为物化表的成本太大,那么它就会被转换为EXISTS查询.


----------------------------------------------------------------------------------------------------------------
EXPLAIN查看执行计划(是在server层的功能):
select_type: 查询的类型. 在包含小查询的查询中,如果我们知道了这个属性,就知道了这这个小查询在整个大查询中扮演了什么角色. 
	   类型:
           ================================================================
			名称						描述
			SIMPLE					查询语句中不包含UNION或者子查询的查询都算作是SIMPLE类型

			PRIMARY					对于包含UNION、UNION ALL或者子查询的大查询来说,它是由几个小查询组成的,
									其中最左边的那个查询的select_type值就是PRIMARY.

			UNION					除了上面说的最左边的那个小查询以外,其余的小查询的select_type值就是UNION.

			UNION RESULT			MySQL选择使用临时表来完成UNION查询的去重工作,针对该临时表的查询的select_type就是UNION RESULT.

			SUBQUERY				如果包含子查询的查询语句不能够转为对应的semi-join的形式,并且该子查询是不相关子查询,
									并且查询优化器决定采用将该子查询物化的方案来执行该子查询时,该子查询的第一个SELECT关键字代
									表的那个查询的select_type就是SUBQUERY(由于物化,所以SUBQUERY只会被执行一次).

			DEPENDENT SUBQUERY		与上面的相同,只不过子查询是相关子查询以及不会被物化(可能被执行多次).

			DEPENDENT UNION			在包含UNION或者UNION ALL的大查询中,如果各个小查询都依赖于外层查询的话,那除了最左边的那个
									小查询之外,其余的小查询的select_type的值就是DEPENDENT UNION.

			DERIVED					对于采用物化的方式执行的包含派生表的查询,该派生表对应的子查询的select_type就是DERIVED.

			MATERIALIZED			当查询优化器在执行包含子查询的语句时,选择将子查询物化之后与外层查询进行连接查询时,
									该子查询对应的select_type属性就是MATERIALIZED.

			UNCACHEABLE SUBQUERY	A subquery for which the result cannot be cached and must be re-evaluated for each row of 
									the outer query

			UNCACHEABLE UNION		The second or later select in a UNION that belongs to an uncacheable subquery (see UNCACHEABLE SUBQUERY)
           ================================================================
           补充:
             SUBQUERY示例SQL: ` EXPLAIN SELECT * FROM s1 WHERE key1 IN (SELECT key1 FROM s2) OR key3 = 'a'; `
type: 
  unique_subquery: 类似于两表连接中被驱动表的eq_ref访问方法,unique_subquery是针对在一些包含IN子查询的查询语句中,
  				   如果查询优化器决定将IN子查询转换为EXISTS子查询,而且子查询可以使用到主键进行等值匹配的话,那么该子查
  				   询执行计划的type列的值就是unique_subquery.
  		  	示例SQL: ` EXPLAIN SELECT * FROM s1 WHERE key2 IN (SELECT id FROM s2 where s1.key1 = s2.key1) OR key3 = 'a'; `	   
   index_subquery: 与unique_subquery类似,只不过访问子查询中的表时使用的是普通的索引.
   			示例SQL: ` EXPLAIN SELECT * FROM s1 WHERE common_field IN (SELECT key3 FROM s2 where s1.key1 = s2.key1) OR key3 = 'a'; `

key_len: key_len列表示当优化器决定使用某个索引执行查询时,该索引记录的最大长度,它是由三个部分构成的:
1. 对于使用固定长度类型的索引列来说,它实际占用的存储空间的最大长度就是该固定值,对于指定字符集的变长类型的索引列来说,
	比如某个索引列的类型是VARCHAR(100),使用的字符集是utf8,那么该列实际占用的最大存储空间就是100 × 3 = 300个字节.
2. 如果该索引列可以存储NULL值,则key_len比不可以存储NULL值时多1个字节.
3. 对于变长字段来说,都会有2个字节的空间来存储该变长列的实际长度.
     用2个字节的原因: 因为EXPLAIN是server层的功能,并且它的目的只是为了让我们区分些索引信息(比如联合索引中具体用了几个索引列).

filter扇出策略:
1. 如果使用的是全表扫描的方式执行的单表查询,那么计算驱动表扇出时需要估计出满足搜索条件的记录到底有多少条.
2. 如果使用的是索引执行的单表扫描,那么计算驱动表扇出的时候需要估计出满足除使用到对应索引的搜索条件外的其他搜索条件的记录有多少条.
   比如: ` EXPLAIN SELECT * FROM s1 WHERE key1 > 'z' AND common_field = 'a'; `
         MySQL会使用`idx_key1`索引来执行查询,那么`filtered`的计算就是满足common_field='a'这个条件的记录数占根据`idx_key1`索引筛选后的
         记录数的百分比.

Extra值含义: 
No tables used: 查询语句的没有FROM子句.
Impossible WHERE: 查询语句的WHERE子句永远为FALSE.
No matching min/max row: 查询列表处有MIN或者MAX聚集函数,但是并没有符合WHERE子句中的搜索条件的记录.
Using index: 查询列表以及搜索条件中只包含属于某个索引的列,也就是在可以使用索引覆盖的情况下,在Extra列将会提示该额外信息.
Using index condition: 搜索条件中虽然出现了索引列,但却不能使用到索引. 比如: ` LIKE '%a'; `
Using where: 当使用全表扫描来执行对某个表的查询,并且该语句的WHERE子句中有针对该表的搜索条件时,在Extra列中会提示上述额外信息.
			 当使用索引访问来执行对某个表的查询,并且该语句的WHERE子句中有除了该索引包含的列之外的其他搜索条件时,在Extra列中也会提示上述额外信息.
Using join buffer (Block Nested Loop): 在连接查询执行过程中,当被驱动表不能有效的利用索引加快访问速度,MySQL一般会为其分配一块名叫join buffer
										的内存块来加快查询速度,也就是基于块的嵌套循环算法.
Not exists: 当使用左(外)连接时,如果WHERE子句中包含要求被驱动表的某个列等于NULL值的搜索条件,而且那个列又是不允许存储NULL值的,
			那么在该表的执行计划的Extra列就会提示Not exists额外信息.
Using intersect(...)、Using union(...)和Using sort_union(...): 说明准备使用对应的索引方式执行查询.
Zero limit: LIMIT子句的参数为0时,表示压根儿不打算从表中读出任何记录,将会提示该额外信息.
Using filesort: 有一些情况下对结果集中的记录进行排序是可以使用到索引的.
Using temporary: 查询的过程中会建立临时表,比如`DISTINCT`、`GROUP BY`、`UNION`等.
Start temporary, End temporary: 子查询时,查询优化器会优先尝试将IN子查询转换成semi-join,而semi-join又有好多种执行策略,
							    当执行策略为DuplicateWeedout时,也就是通过建立临时表来实现为外层查询中的记录进行去重操作时,
							    驱动表查询执行计划的Extra列将显示Start temporary提示,被驱动表查询执行计划的Extra列将显示
							    End temporary提示.
LooseScan: 在将In子查询转为semi-join时,如果采用的是LooseScan执行策略,则在驱动表执行计划的Extra列就是显示LooseScan提示.
FirstMatch(tbl_name): 在将In子查询转为semi-join时,如果采用的是FirstMatch执行策略,则在被驱动表执行计划的Extra列就是显示
					  FirstMatch(tbl_name)提示.

查看执行计划详细信息: 
语法: EXPLAIN FORMAT=JSON [SQL];
返回部分截取:
```
"cost_info": {
	"read_cost": "1840.84",     
	"eval_cost": "193.76",      
	"prefix_cost": "2034.60",   # 单次查询s1表总共的成本
	"data_read_per_join": "1M"  # 读取的数据量
}
```
read_cost: 由'IO成本'和'检测rows*(1-filter)条记录的CPU成本'.  `rows`和`filter`都是FORMAT=JSON返回的字段.
eval_cost: 检测'rows * filter'条记录的成本.  eval: 评估.
prefix_cost: 单独查询s1表的成本. 也就是: read_cost + eval_cost;

注意: 书上说主要是观察'prefix_cost'的成本值,没必要关注为什么计算出'read_cost'和'eval_cost'.
	  还有,被驱动表的'prefix_cost'是额外加上了驱动表的'prefix_cost'成本.

查看MYSQL内部(优化后)执行SQL语句:
语法: 执行完SQL后再执行: ` SHOW WARNINGS; `.
返回示例:
```
*************************** 1. row ***************************
Level: Note
Code: 1003
Message: /* select#1 */ select `xiaohaizi`.`s1`.`key1` AS `key1`,`xiaohaizi`.`s2`.`key1` AS `key1` from `xiaohaizi`.`s1` join `xiaohaizi`.`s2` where ((`xiaohaizi`.`s1`.`key1` = `xiaohaizi`.`s2`.`key1`) and (`xiaohaizi`.`s2`.`common_field` is not null))
1 row in set (0.00 sec)
```
说明: 最常见的就是code=1003,Message字段展示的信息类似于查询优化器将我们的查询语句重写后的SQL. 需要注意的是并不是等价于最终执行SQL,只是一个参考依据!


------------------------------------------------------------------------------------------------------------------------
基于成本的优化主要集中在optimize阶段,对于单表查询来说,我们主要关注optimize阶段的"rows_estimation"这个过程,这个过程深入分析了对单表查询的各种执行方案的成本;对于多表连接查询来说,我们更多需要关注"considered_execution_plans"这个过程,这个过程里会写明各种不同的连接方式所对应的成本


------------------------------------------------------------------------------------------------------------------------
即使我们只需要访问一个页的一条记录,那也需要先把整个页的数据加载到内存中

Buffer Pool
链接: [Buffer Pool](https://juejin.im/book/5bffcbc9f265da614b11b731/section/5c238f0851882521eb44c51f)
配置: 
```
[server]
# 单位: 字节
innodb_buffer_pool_size = 268435456
```

LSN(Log Sequeue Number):
链接: [掘金](https://juejin.im/book/5bffcbc9f265da614b11b731/section/5c7522daf265da2de165acc3)
说明: 记录写入的redo log日志量. 初始值为8704. 实际上统计lsn的增长量时,时按照log block body(实际写入的日志量)
	   +log block header + log block trailer.

暂时把每个页对应的控制信息占用的一块内存称为一个'控制块'. 控制块和缓存页是一一对应的,它们都被存放到Buffer Pool
中,其中控制块被存放到Buffer Pool的前边,缓存页被存放到Buffer Pool后边

Buffer Pool里的一些链表:
free链表: 存放空闲缓存页.
flush链表: 存放脏页.
LRU链表: 用于清除不常用数据.
划分区域的LRU链表:
  背景: 普通LRU链表会因为'InnoDB预读'、'扫描全表'导致'劣币驱逐良币'现象.
  介绍: 将LUR链表分成两个区域: young区域、old区域.
  查看: 通过'innodb_old_blocks_pct'的值来查看old区域占比.
  具体: 
  	   *针对预读的页面可能不进行后续访情况的优化: 当磁盘上的某个页面在初次加载到Buffer Pool
  	   						中的某个缓存页时,该缓存页对应的控制块会被放到old区域的头部.这样针对预读到Buffer Pool
  	   						却不进行后续访问的页面就会被逐渐从old区域逐出,而不会影响young区域中被使用比较频繁的缓存页.

  	   *针对全表扫描时,短时间内访问大量使用频率非常低的页面情况的优化: 在对某个处在old区域的缓存页进行第一次访问时就在它对应的控制
  	   						块中记录下来这个访问时间,如果后续的访问时间与第一次访问的时间在某个时间间隔内(系统变量innodb_old_blocks_time),
  	   						那么该页面就不会被从old区域移动到young区域的头部,否则将它移动到young区域的头部.

进一步优化LRU链表: 为了避免频繁的对LRU链表进行节点移动操作,只有被访问的缓存页位于young区域的1/4的后边,才会被移动到LRU链表头部.

多个Buffer Pool实例有利于多线程加锁时的访问速度:
配置:
```
[server]
innodb_buffer_pool_instances = 2
```
每个Buffer Pool实例实际占多少内存空间 = innodb_buffer_pool_size/innodb_buffer_pool_instances
注意: 当innodb_buffer_pool_size的值小于1G的时候设置多个实例是无效的

Buffer Pool Chunk:
  原因: Buffer Pool的大小只能在服务器启动时通过配置innodb_buffer_pool_size启动参数来调整大小,在服务器运行过程中是不允许调整该值的.
  	    不过设计MySQL的大叔在5.7.5以及之后的版本中支持了在服务器运行过程中调整Buffer Pool大小的功能,但是有一个问题,就是每次当我们要
  	    重新调整Buffer Pool大小时,都需要重新向操作系统申请一块连续的内存空间,然后将旧的Buffer Pool中的内容复制到这一块新空间,这是极
  	    其耗时的.所以设计MySQL的大叔们决定不再一次性为某个Buffer Pool实例向操作系统申请一大片连续的内存空间,而是以一个所谓的chunk为单位
  	    向操作系统申请空间.也就是说一个Buffer Pool实例其实是由若干个chunk组成的,一个chunk就代表一片连续的内存空间,里边儿包含了若干缓存页
  	    与其对应的控制块.

  配置:
		```
		[server]
		# 单位: 字节
		innodb_buffer_pool_chunk_size=134217728
		```
  注意: 
	1. 这个chunck的大小是在服务器运行过程中不能修改的.
	2. innodb_buffer_pool_size必须是innodb_buffer_pool_chunk_size × innodb_buffer_pool_instances的倍数.
	   这主要是想保证每一个Buffer Pool实例中包含的chunk数量相同.

Buffer Pool的缓存页除了用来缓存磁盘上的页面以外,还可以存储锁信息、自适应哈希索引等信息.

查看关于InnoDB存储引擎运行过程中的一些状态信息:
命令: ` SHOW ENGINE INNODB STATUS; `
信息: 
=========================================================================================
属性名								含义
Total memory allocated 				代表Buffer Pool向操作系统申请的连续内存空间大小,包括全部控制块、缓存页、以及碎片的大小

Dictionary memory allocated 		为数据字典信息分配的内存空间大小,这个内存空间和Buffer Pool没啥关系,不包括在Total memory allocated中

Buffer pool size 					代表该Buffer Pool可以容纳多少缓存页

Free buffers 						代表当前Buffer Pool还有多少空闲缓存页,也就是free链表中还有多少个节点

Database pages 						代表LRU链表中的页的数量,包含young和old两个区域的节点页面数量

Old database pages 					代表LRU链表old区域的节点页面数量

Modified db pages 					代表脏页数量,也就是flush链表中节点的页面数量

Pending reads 						正在等待从磁盘上加载到Buffer Pool中的页面数量

Pending writes LRU 					即将从LRU链表中刷新到磁盘中的页面数量

Pending writes flush list 			即将从flush链表中刷新到磁盘中的页面数量

Pending writes single page 			即将以单个页面的形式刷新到磁盘中的页面数量

Pages made young 					代表LRU链表中曾经从old区域移动到young区域头部的节点数量

Page made not young 				在将innodb_old_blocks_time设置的值大于0时,首次访问或者后续访问某个处在old区域的节点时由于不符合时间间隔
									的限制而不能将其移动到young区域头部时,Page made not young的值会加1

youngs/s 							代表每秒从old区域被移动到young区域头部的节点数量

non-youngs/s 						代表每秒由于不满足时间限制而不能从old区域移动到young区域头部的节点数量

Pages read、created、written 			代表读取,创建,写入了多少页.后边跟着读取、创建、写入的速率

Buffer pool hit rate 				表示在过去某段时间,平均访问1000次页面,有多少次该页面已经被缓存到Buffer Pool了

young-making rate 					表示在过去某段时间,平均访问1000次页面,有多少次访问使页面移动到young区域的头部了(包括blocks_times和1/4的因素)

not (young-making rate) 			表示在过去某段时间,平均访问1000次页面,有多少次访问没有使页面移动到young区域的头部(因素同上)

LRU len								代表LRU链表中节点的数量

unzip_LRU							代表unzip_LRU链表中节点的数量

I/O sum								最近50s读取磁盘页的总数

I/O cur								现在正在读取的磁盘页数量

I/O unzip sum						最近50s解压的页面数量

I/O unzip cur						正在解压的页面数量
=========================================================================================


==========================================================================================
redo log临时笔记:
info bits: 表示记录头信息的前4个比特位的值以及record_type的值.

对底层页面中的一次原子访问的过程称之为一个Mini-Transaction,简称mtr.

mtr生成的redo log放在了大小为512字节的页中.(暂时叫block)
一个block可以存放多个mtr,并且存放在log block body中. 全部填满则为512字节.

redo log buffer(log buffer): 为了解决磁盘速度过慢的问题而用来缓存redo log的.

buf_free全局变量: 用来指明后续写入的redo日志应该写入到log buffer中起始的哪个位置.

flush链表刷新到磁盘是从链表后面开始往前刷新.

我记得在mysql技术内幕里面讲过,重做日志块的大小和磁盘扇区大小一样,都是512字节了,因此重做日志的写入可以保证原子性,
不需要doublewrite技术. TODO
==========================================================================================

------------------------------------------------------------------------------------------
undo log:

事务id怎么生成的:
1. 服务器会在内存中维护一个全局变量,每当需要为某个事务分配一个事务id时,就会把该变量的值当作事务id分配给该事务,并且把该变量自增1.
2. 每当这个变量的值为256的倍数时,就会将该变量的值刷新到系统表空间的页号为5的页面中一个称之为Max Trx ID的属性处,这个属性占用8个字节的存储空间.
3. 当系统下一次重新启动时,会将上边提到的Max Trx ID属性加载到内存中,将该值加上256之后赋值给我们前边提到的全局变量
   (因为在上次关机时该全局变量的值可能大于Max Trx ID属性值).

事务id和roll_pointer都是Compact行格式里的扩展字段(属于隐藏列)
undo_demo table_id为7597
事务id的分配和row_id的分配类似. roll_pointer本质上是指向一个undo记录的指针(7个字节).
将被删除记录加入到垃圾链表时,实际上加入到链表的头节点处,会跟着修改PAGE_FREE属性的值

TRX_UNDO_DEL_MARK_REC类型的undo日志:
info bits: 
记录old trx_id、old roll_pointer后就可以通过old roll_pointer找到记录在修改前对应的undo log.
索引列各列信息<pos,len,value>: 包括该列在记录中的位置(用pos表示),该列占用的存储空间大小(用len表示),该列实际值(用value表示). 
                              主要用于在事务提交后对该'中间状态记录'做真正删除的阶段二(purge阶段).

TRX_UNDO_UPD_EXIST_REC类型的undo日志:
n_updated: 共有多少个列被更新了.
注意: n_updated后边跟着的<pos, old_len, old_value>分别表示被更新列在记录中的位置、更新前该列占用的存储空间大小、更新前该列的真实值(注意下'更新前').
     如果在UPDATE语句中更新的列包含索引列,那么也会添加索引列各列信息这个部分,否则的话是不会添加这个部分的.

问: 为什么update时,对于不更新主键并且前后大小不一致的记录,可以直接删除并加入垃圾链表;而对更新主键的update操作,却使用delete mask的方式来标记删除?
答: (猜测一),如果不是主键更新的话,即使删掉了记录,新的记录主键也一样,那么就可以找到这个主键,然后通过roll_pointer构成版本链; 如果是更新主键的话,如果也是
    直接删除,那么就无法在这个页面找到这个记录了,这样的话就无法根据这条记录的roll_pointer找到版本链了,所以先标记删除再插入.
    (猜测二),直接删除数据是因为innodb其实初衷还是想复用以前数据的分配空间的(毕竟起码聚簇索引不用改),但是无奈不能用了,所以只能直接删掉再重新分配空间.
    这个猜测的基点是在'delete_mark会触发索引等一系列的数据清除,而直接删数据再分配不会触发'上的.

------------------------------------------------------------------------------------------------------------------------------------
FIL_PAGE_UNDO_LOG页结构:
	Undo Page Header:
		结构介绍:  
			TRX_UNDO_PAGE_TYPE(2字节): 本页面准备存储什么种类的undo log.
			   TRX_UNDO_INSERT(01): 类型为TRX_UNDO_INSERT_REC的undo日志属于此大类,一般由INSERT语句产生,
			   						  或者在UPDATE语句中有更新主键的情况也会产生此类型的undo log.
			   TRX_UNDO_UPDATE(10): 除了类型为TRX_UNDO_INSERT_REC的undo日志,其他类型的undo日志都属于这个大类,
			   						比如TRX_UNDO_DEL_MARK_REC、TRX_UNDO_UPD_EXIST_REC等,一般由DELETE、UPDATE
			   						语句产生的undo日志属于这个大类.
			TRX_UNDO_PAGE_START(2字节): 表示第一条undo日志在本页面中的起始偏移量.
			TRX_UNDO_PAGE_FREE(2字节): 表示当前页面中存储的最后一条undo日志结束时的偏移量. 从这个位置开始,
										可以继续写入新的undo日志.
			TRX_UNDO_PAGE_NODE(12字节): 一个List Node结构,undo页面可以通过这个属性连成一个链表.
说明: 之所以把undo日志分成两个大类,是因为类型为TRX_UNDO_INSERT_REC的undo日志在事务提交后可以直接删除掉,而其他类型的undo日志还需要为所谓的MVCC服务,
	  不能直接删除掉,对它们的处理需要区别对待.

first undo page: 通过TRX_UNDO_PAGE_NODE组成的链表中的第一个undo页,除了记录Undo Page Header之外,还会记录其他的一些管理信息. 
  				 比如: Undo Log Segment Header、Undo Log Header.

一个事务中最多有4个以undo页为节点组成的链表: 分为两大类'普通表'、'临时表',每类都可以有'insert undo'、'update undo'
										   类型的链表. 
								    注意: 这个分配是'按需分配',意思就是需要分配的时候再分配,不是开启了事务就直接分配.

Undo Log Segment Header: 每一个undo页面链表都对应一个段,称为undo log segment,也就是说链表中的页面都是从这个段里面申请的.
						 所以他们在undo页面链表的第一个页面(first undo page)中设计了一个称之为Undo Log Segment Header的部分
						 这个部分中包含了该链表对应的段的segment header信息以及其他的一些关于这个段的信息. 
			    结构介绍: 
			    	   TRX_UNDO_STATE: 本undo页面链表处在什么状态. 
			    	   				包含:
			    	   					TRX_UNDO_ACTIVE: 一个活跃的事务正在往这个段里边写入undo日志.
			    	   					TRX_UNDO_CACHED: 处在该状态的undo页面链表等待着之后被其他事务重用.
			    	   					TRX_UNDO_TO_FREE: 对于insert undo链表来说,如果在它对应的事务提交之后,该链表不能被重用,那么就会处于这种状态.
			    	   					TRX_UNDO_TO_PURGE: 对于update undo链表来说,如果在它对应的事务提交之后,该链表不能被重用,那么就会处于这种状态.
			    	   					TRX_UNDO_PREPARED: 	包含处于PREPARE阶段的事务产生的undo日志(在分布式事务中才会出现该状态).
			    	TRX_UNDO_LAST_LOG: 本undo页面链表中最后一个Undo Log Header的位置.
			     TRX_UNDO_FSEG_HEADER: 本undo页面链表对应的段的Segment Header信息.
			       TRX_UNDO_PAGE_LIST: undo页面链表的基节点(TRX_UNDO_PAGE_NODE组成的链表的基节点,当然这个节点只存在于first undo page中). 
						 
Undo Log Header: 一个undo页面链表代表一组(注意是"undo页面链表"),在每写入一组undo log时,都会在这组undo log前先记录一下关于这组的一些属性,
				  undo log header便是存储这些属性的地方.
	    结构介绍:
	           TRX_UNDO_TRX_ID: 生成本组undo日志的事务id.
	           TRX_UNDO_TRX_NO: 事务提交后生成的一个需要序号,使用此序号来标记事务的提交顺序(先提交的此序号小,后提交的此序号大).
	        TRX_UNDO_DEL_MARKS: 标记本组undo日志中是否包含由于delete mark操作产生的undo日志.
	        TRX_UNDO_LOG_START: 表示本组undo日志中第一条undo日志的在页面中的偏移量.
	       TRX_UNDO_XID_EXISTS: 本组undo日志是否包含XID信息. 
	       TRX_UNDO_DICT_TRANS: 标记本组undo日志是不是由DDL语句产生的.
	         TRX_UNDO_TABLE_ID: 如果TRX_UNDO_DICT_TRANS为真,那么本属性表示DDL语句操作的表的table id.
	         TRX_UNDO_NEXT_LOG: 下一组的undo日志在页面中开始的偏移量(重用时候的'组').
	         TRX_UNDO_PREV_LOG: 上一组的undo日志在页面中开始的偏移量(同上).
		 TRX_UNDO_HISTORY_NODE: 一个12字节的List Node结构,代表一个称之为History链表的节点(下面有介绍).

TRX_UNDO_HISTORY_NODE介绍: 如果当前undo log(链表)类型为update并且事务提交了并且不满足加入cached链表,则会将其在对应的roll back segment中对应的slot
						  设置为FIL_NULL,并且将undo log加入history list中(它在Roll back Segment Header中),history list中的节点指针就是undo log header的
						  TRX_UNDO_HISTORY_NODE(也就是这个).
				     参考: [taobao数据库内核月报](http://mysql.taobao.org/monthly/2015/04/01/)

小结: 对于没有重用的undo页面链表来说,链表的第一个页面,也就是first undo page在真正写入undo log前,会填充Undo Page Header、Undo Log Segment Header、
	  Undo Log Header这3个部分,之后才开始正式写入undo日志.对于其他的页面来说,在真正写入undo日志前,只会填充Undo Page Header.链表的
	  List Base Node存放到first undo page的Undo Log Segment Header部分,List Node信息存放到每一个undo页面的undo Page Header部分.

---分割线---

重用策略: 为了解决undo页面链表存储不饱满问题,决定在事务提交后在某些情况下重用该事务的undo页面链表:
			      	  该链表中只包含一个undo页面: 多页面的情况下维护、可用方面不可观.
	该undo页面已经使用的空间小于整个页面空间的3/4: 分insert undo链表和update undo链表两种情况.
	             		  	   			insert undo链表: 这种类型的undo日志在事务提交之后就没用了,就可以被清除掉.所以在某个事务提交后,
	             		  	   			           重用这个事务的insert undo链表(这个链表中只有一个页面)时,可以直接把之前事务写入的一组undo日志覆盖掉,
	             		  	   		               从头开始写入新事务的一组undo日志(包括维护Undo Page Header、Undo Log Segment Header
	             		  	   		               、Undo Log Header中的一些属性).
  									    update undo链表: 在一个事务提交后,它的update undo链表中的undo日志也不能立即删除掉(这些日志用于MVCC).
  									    				所以如果之后的事务想重用update undo链表时,就不能覆盖之前事务写入的undo日志.这样就相当于
  									    				在同一个undo页面中写入了多组的undo日志.

Rollback Segment Header: 
				   说明: 由于同一时刻系统里可以有很多个undo页面链表存在,为了更好的管理这些链表,设计了这个Rollback Segment Header页面.
						 它存放了各个undo页面链表的first undo page的页号,并把每个页号都称为undo slot.通过这些first undo page,可以访问到
						 各个事务的undo log链表.

                   其它: 每个Rollback Segment Header页面都对应着一个段,称为Rollback Segment(可以叫'回滚段').
						 一个这个页面能包含1024个undo slot,FIL_NULL(0XFFFFFFFF)用来标识当前undo solot是否已经被别的事务占用了(已经
						 存放了别的first undo page). 

                   注意: 如果Rollback Segment Header中的1024个undo solt都不为FIL_null,那么此时不能再获得新的undo页面链表,所以会报错.

               结构介绍:
                       TRX_RSEG_MAX_SIZE: 本Rollback Segment中管理的所有undo页面链表中的undo页面数量之和的最大值.
                   TRX_RSEG_HISTORY_SIZE: History链表占用的页面数量(看Undo Log Header的TRX_UNDO_HISTORY_NODE介绍).
                   	    TRX_RSEG_HISTORY: History链表的基节点(同上).
                   	TRX_RSEG_FSEG_HEADER: 本Rollback Segment对应的10字节大小的Segment Header结构,通过它可以找到本段对应的INODE Entry.
                   	 TRX_RSEG_UNDO_SLOTS: 各个undo页面链表的first undo page的页号集合,也就是undo slot集合.

当一个事务提交时,它所占用的undo slot有两种命运:
1. 如果该undo slot指向的undo页面链表符合被重用的条件,那么该undo slot就处于被缓存的状态(该undo页面链表的TRX_UNDO_STATE为TRX_UNDO_CACHED).
   被缓存的undo slot都会被加入到某个链表,如果对应的undo页面链表是insert undo链表,则该undo slot会被加入insert undo cached链表,如果对应的
   undo页面链表是update undo链表,则该undo slot会被加入update undo cached链表.

2. 如果不符合被重用的条件,那么:
   2.1: 如果对应的undo页面链表是insert undo链表,则该undo页面链表的TRX_UNDO_STATE属性会被设置为TRX_UNDO_TO_FREE,之后该undo页面链表对应的段
        会被释放掉(复习: 每一个undo页面链表都对应一个段--Undo Log Segment Header),然后把该undo slot的值设置为FIL_NULL.

   2.2: 如果对应的Undo页面链表是update undo链表,则该Undo页面链表的TRX_UNDO_STATE属性会被设置为TRX_UNDO_TO_PURGE,则会将该undo slot的值设置
   		为FIL_NULL,然后将本次事务写入的一组undo日志放到的History链表中(需要注意的是,这里并不会将Undo页面链表对应的段给释放掉,
   		因为这些undo日志还有用).
注意:cached链表是对应Rollback Segment的. 

多个'回滚段':
  说明: 一个事务最多分配4个Undo页面链表,而一个回滚段里最多1024个undo slot,显然支持某个时间段存活的事务很少,所以InnoDB定义了128个回滚段,
它们存放在系统表空间的第5号页面的某个区域.
  结构: SpaceID(4字节)+Page Number(4字节) ==> 表空间ID + 页号
 		这意味着不同的回滚段可能分布在不同的表空间中. 

[最终结构图](https://i.loli.net/2020/01/16/BytfXs91GPOrmVN.png)

临时表对应的回滚段存储空间和普通表对应的回滚段的不同.

回滚段的分类: 
0号、33~127号回滚段: 其中第0号回滚段必须在系统表空间中,第33～127号回滚段既可以在系统表空间中,也可以在自己配置的undo表空间中.
				    如果一个事务在执行过程中由于对普通表的记录做了改动需要分配undo页面链表时,必须从这一类的段中分配相应的undo slot.
1～32号: 这些回滚段必须在临时表空间.
 		  如果一个事务在执行过程中由于对临时表的记录做了改动需要分配undo页面链表时,必须从这一类的段中分配相应的undo slot
配置: 通过在配置文件[server]下配置innodb_rollback_segments来设置,可配置范围是1~128,但是这个参数并不会影响针对临时表的回滚段数量,
	  针对临时表的回滚段数量一直是32. 也就是说这个值包含了临时表空间的数(取2~33和1没区别). 

为事务分配undo页面链表: 略.
				注意: 如果一个事务在执行过程中既对普通表的记录做了改动,又对临时表的记录做了改动,那么需要为这个记录分配2个回滚段.
					  并发执行的不同事务其实也可以被分配相同的回滚段,只要分配不同的undo slot就可以了.
==========================================================================================


------------------------------------------------------------------------------------------
事务隔离级别和MVCC临时笔记:

隐式事务: 语句结束事务就提交了.

下面是SQL标准定义:

脏写(Dirty Write): 一个事务修改了另一个未提交事务修改过的数据.
脏读(Dirty Read): 一个事务读到了另一个未提交事务修改过的数据.
不可重复读(Non-Repeatable Read): 一个事务只能读到另一个已经提交的事务修改过的数据,并且其他事务每对该数据进行一次修改并提交后,
								  该事务都能查询得到最新值. 等于就是一个事务多次读发现值都不一样.
	[示例图](https://user-gold-cdn.xitu.io/2019/4/18/16a2f5b32bc1f76b?imageView2/0/w/1280/h/960/format/webp/ignore-error/1)
幻读(Phantom): 一个事务先根据某些条件查询出一些记录,之后另一个事务又向表中插入了符合这些条件的记录,原先的事务再次按照该条件查询时,
				 能把另一个事务插入的记录也读出来.
		 注意: 如果Session B中是删除了一些符合number > 0的记录而不是插入新记录,那Session A中之后再根据number > 0的条件读取的记录变少了,
		   	   这种现象不属于幻读,幻读强调的是一个事务按照某个相同条件多次读取记录时,后读取时读到了之前没有读到的记录. 对于先前已经读到的记录,
		   	   之后又读取不到的情况,这相当于对每一条记录都发生了不可重复读的现象. 幻读强调了读取到了之前读取没有获取到的记录.

4个隔离级别: READ UNCOMMITTED(未提交读)、READ COMMITTED(已提交读)、REPEATABLE READ(可重复读)、SERIALIZABLE(可串行化)

--------------------------------------------------------------------------------
隔离级别				脏读				不可重复读		幻读
READ UNCOMMITTED	Possible		Possible		Possible
READ COMMITTED		Not Possible	Possible		Possible
REPEATABLE READ		Not Possible	Not Possible	Possible
SERIALIZABLE		Not Possible	Not Possible	Not Possible
--------------------------------------------------------------------------------
注意: 不论是哪种隔离级别,都不允许脏写的情况发生. 
     上面是SQL标准定义,但MySQL在REPEATABLE READ隔离级别下,是可以禁止幻读问题的发生的.

需要判断一下版本链中的哪个版本是当前事务可见的.

ReadView判断记录的某个版本是否可见的规则:
*: 如果被访问版本的trx_id属性值与ReadView中的creator_trx_id值相同,意味着当前事务在访问它自己修改过的记录,所以该版本可以被当前事务访问.

*: 如果被访问版本的trx_id属性值小于ReadView中的min_trx_id值,表明生成该版本的事务在当前事务生成ReadView前已经提交,所以该版本可以被当前事务访问.

*: 如果被访问版本的trx_id属性值大于或等于ReadView中的max_trx_id值,表明生成该版本的事务在当前事务生成ReadView后才开启,所以该版本不可以被当前事务访问.

*: 如果被访问版本的trx_id属性值在ReadView的min_trx_id和max_trx_id之间,那就需要判断一下trx_id属性值是不是在m_ids列表中,如果在,说明创建ReadView时
   生成该版本的事务还是活跃的,该版本不可以被访问;如果不在,说明创建ReadView时生成该版本的事务已经被提交,该版本可以被访问.

RC和RR隔离级别在MVCC中的不同: 
READ COMMITTED: 每次查询开始时都会生成一个独立的ReadView.
REPEATABLE READ: 只会在第一次执行查询语句时生成一个ReadView,之后的查询就不会重复生成了.

所谓的MVCC只是在我们进行普通的SELECT查询时才生效,截止到目前我们所见的所有SELECT语句都算是普通的查询
==========================================================================================

==========================================================================================
锁临时笔记:
解决脏读、不可重复读、幻读这些问题:
方案一: 读操作利用多版本并发控制(MVCC),写操作进行加锁.
方案二: 读、写操作都采用加锁的方式.
==========================================================================================

------------------------------------------------------------------------------------------
general log:
说明: 开启general log会将所有到达MySQL Server的SQL语句记录下来,一般用于故障排除.
文档: [query log介绍](https://dev.mysql.com/doc/refman/5.7/en/query-log.html)
	  、[log_output介绍](https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html#sysvar_log_output)  
相关参数: general_log、log_output、general_log_file
     general_log: 用于开关.
      log_output: 多选,逗号分隔,可取FILE、TABLE、NONE(默认). 
    			  为NONE则general_log开启了也不会记录log; 	
    			  TABLE方式默认在存到mysql.general_log表中.方便各种查询.
general_log_file: 日志文件名,不指定的话默认为${hostname}.log,位于${datadir}数据目录下.

补充: `log_output=table`时创建的表结构:
```
CREATE TABLE `general_log` (
  `event_time` timestamp(6) NOT NULL DEFAULT CURRENT_TIMESTAMP(6) ON UPDATE CURRENT_TIMESTAMP(6),
  `user_host` mediumtext NOT NULL,
  `thread_id` bigint(21) unsigned NOT NULL,
  `server_id` int(10) unsigned NOT NULL,
  `command_type` varchar(64) NOT NULL,
  `argument` mediumblob NOT NULL
) ENGINE=CSV DEFAULT CHARSET=utf8 COMMENT='General log'
```
存储引擎为CSV,它的数据会直接存储到.csv文件中,存储引擎可以按需更改.

---------------------------------------------------------------------------------------
mysql慢查询日志(slow-query-log):
说明: 日志由SQL语句组成,可用于分析执行时间较长的查询. TODO 分析工具
文档: [slow-query-log介绍](https://dev.mysql.com/doc/refman/5.7/en/slow-query-log.html)
      它里面记录了其它参数具体含义以及用法.
相关参数: slow_query_log(开关)、long_query_time、slow_query_log_file(记录的文件的绝对路径)
	long_query_time(单位: 秒): 设置大于long_query_time秒的查询语句会被记录.

补充:
1. 注意之前介绍`general log`时配置的`log_output`参数不仅仅影响`general log`的存储方式还影响`slow query log`的存储方式.

2. slow-query-log记录的内容:
	```
	SET timestamp=1581303604;
	select * from single_table2 where common_field NOT   like '%1EER%' OR key_part3 LIKE '%Y4483FAY%';
	# Time: 2020-02-10T03:05:22.213741Z
	# User@Host: root[root] @ localhost [::1]  Id:    23
	# Query_time: 0.152589  Lock_time: 0.000998 Rows_sent: 67319  Rows_examined: 99982
	```

日志分析工具: mysql有个专门分析这个的脚本,在${MYSQL_HOME}\bin\mysqldumpslow.pl中,需要<code>perl</code>环境才能跑.
          使用命令: `perl mysqldumpslow.pl -s -r -t 20 ${datadir}\mysql-slow.log`
             提示: 参数含义也可以看`mysqldumpslow.pl`代码批注.
             介绍: 它主要还是用于过滤、排序日志.

---------------------------------------------------------------------------------------
问: 同样都是使用B+Tree,InnoDB和MyISAM的实现细节有什么区别?
答:
	主键索引：主要区别是聚集索引和非聚集索引上,前者除了保存主键外还有数据,后者除了主索引key外只保存记录的地址
			address(可以理解为行号)
	辅助索引：前者叶节点中保存的是辅助索引key和主键索引的值PK,后者保存的是辅助索引key和对应的主键索引的地址
			 address(可以理解为行号)
			   所以MyISAM的索引文件和数据文件是彼此独立存在的,并且MyISAM的主键索引和辅助索引在存储结构上是一样的,都
			 是在叶子节点上保存了
		       数据的地址,唯一不同的是辅助索引的关键字是允许重复的.对于通过辅助索引来检索记录的操作来说,由于InnoDB存储
		     的是主键的值,还需要再次查询主键索引才可以获得记录的内容,而MyISAM存储的也是主键行号,可以直接读取行号对应的
		     记录内容(不需要从B+Tree里查找)

问: InnoDB的辅助索引的叶子节点存储主键的值而不是地址,好处是什么?
答: 减少了当出现行记录移动或者数据页分裂时辅助索引的维护工作,虽然使用主键值当作指针会让辅助索引占用更多空间,但好处是,
	Innodb在移动行时无需更新辅助索引中的主键值,而MyISAM 需要调整其辅助索引的叶子节点中保存的主键的地址.

问: MySQL运行中,需要保证Binlog和Redo Log的一致性,如果顺序不一致,则意味着Master-Slave可能不一致,它是怎么保证的?
答: 二阶段提交,内部会自动将普通事务当做一个XA事务(内部分布式事务)来处理:
	1. Commit会被自动的分成Prepare和Commit两个阶段
	2. Binlog会被当做事务协调者(Transaction Coordinator),Binlog Event会被当做协调者日志

	当有事务提交时: 
	1. InnoDB进入Prepare阶段,并且write/sync redo log,写redo log,将事务的XID写入到redo日志中,binlog不作任何操作
	2. 进行write/sync Binlog,写binlog日志,也会把XID写入到Binlog
	3. 调用InnoDB引擎的Commit完成事务的提交,将Commit信息写入到redo日志中

	如果是在第一步和第二步失败,则整个事务回滚;如果是在第三步失败,则MySQL在重启后会检查XID是否已经提交,若没有提交,
	也就是事务需要重新执行,就会在存储引擎中再执行一次提交操作,保障redo log和binlog数据的一致性,防止数据丢失.

	在实际执行中,还牵扯到操作系统缓存Buffer何时同步到文件系统中,所以MySQL支持用户自定义在Commit时如何将log buffer 中的日志刷到log file中,通过变量innodb_flush_log_at_trx_Commit的值来决定.在log buffer中的内容称为脏日志.(全局
	搜下log buffer)

	如果要严格保证数据不丢失,必须得保证innodb_flush_log_at_trx_commit配置为1. 
	  如果配置成0,则redo log即使标记为commit状态了,由于此时redo log处于redo log buffer中,如果断电,
	redo log buffer内存中的数据会丢失,此时如果恰好buffer pool中的脏页也还没有刷新到磁盘,而redo log也丢失了,
	所以在MySQL重启后,由于丢失了一条redo log,因此就会丢失一条redo log对应的重做日志,这样断电前提交的那一次事
	务的数据也就丢失了
	  如果配置成2,则事务提交时,会将redo log buffer(实际上是此次事务所对应的那条redo log所在的redo log block
	写入磁盘,但是操作系统通常都会存在os cache,所以这时候的写只是将数据写入到了os cache,如果机器断电,数据依然会
	丢失.
	  而如果配置成1(默认),则表示事务提交时,就将对应的redo log block写入到磁盘,同时调用fsync,fsync会将数据强制从
	os cache中刷入到磁盘中,因此数据不会丢失.
	  从效率上来说,0的效率最高,因为不涉及到磁盘IO,但是会丢失数据;而1的效率最低,但是最安全,不会丢失数据.2的效
	率居中,会丢失数据.在实际的生产环境中,通常要求是的是"双1配置",即将innodb_flush_log_at_trx_commit设置为1,
	另外一个1指的是写binlog时,将sync_binlog设置为1,这样binlog的数据就不会丢失.

问: MySQL的Binlog数据类型有哪些?
答: 包括以下三种：
	1. statement 格式,记录为基本语句,包含 Commit
	2. row 格式,记录为基于行
	3. mixed 格式,日志记录使用混合格式
	
	PS: 不论是statement还是row格式,binlog都会添加一个XID_EVENT作为事务的结束,该事件记录了事务的ID也就是Xid,
		在MySQL进行崩溃恢复时根据binlog中提交的情况来决定如何恢复

