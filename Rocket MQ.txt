Rocket MQ笔记

参考: https://github.com/apache/rocketmq/tree/master/docs/cn
	 、https://me.csdn.net/prestigeding

启动: mqbroker.cmd -n localhost:9876 autoCreateTopicEnable=true

问: rocketmq里的groupname是什么作用,同一个发布组中的producer订阅了不同的主题,会影响消息的发布吗?
答: 作用是在集群HA的情况下,一个生产者down之后,本地事务回滚后,可以继续联系该组下的另外一个生产者实例,不至于导致业务走不下去.在消费者组中,可以实现消息消费的负载均衡和消息容错目标.

另外,有了GroupName,在集群下,动态扩展容量很方便.只需要在新加的机器中,配置相同的GroupName.启动后,就立即能加入到所在的群组中,参与消息生产或消费.

------------------------------------------数据结构-----------------------------------
CommitLog: 
所有主题的消息随着到达 Broker 的顺序写入 CommitLog 文件,每个文件默认为1G. 文件的命名使用该存储在消息文件
中的第一个全局偏移量来命名文件,方便根据消息的物理偏移量,快速定位到消息所在的物理文件. 并且采用顺序写.

ConsumeQueue:
基于Topic的索引文件,主要用于消费者根据Topic|Tag消费消息. 

数据结构: CommitLog物理偏移量+消息长度+Tag HashCode. 8+4+8,总共20个字节,tag hash是为了对齐大小.
存储路径: topic/queue/file.

MQ基于JSON的协议: https://zhuanlan.zhihu.com/p/30875730

------------------------------------------Producer-----------------------------------
发送结果分四种: 
SEND_OK,			 //状态成功,无论同步还是存储.
FLUSH_DISK_TIMEOUT,  // broker刷盘策略为同步刷盘(SYNC_FLUSH)的话时候,等待刷盘的时候超时.
FLUSH_SLAVE_TIMEOUT, // master role采取同步复制策略(SYNC_MASTER)的时候,消息尝试同步到slave超时.
SLAVE_NOT_AVAILABLE, //slave不可用.

------------------------------------------刷盘机制-----------------------------------
https://github.com/apache/rocketmq/blob/master/docs/cn/design.md
同步刷盘: 只有在消息真正持久化至磁盘后RocketMQ的Broker端才会真正返回给Producer端一个成功的ACK响应.
		 同步刷盘对MQ消息可靠性来说是一种不错的保障,但是性能上会有较大影响,一般适用于金融业务应用
		 该模式较多.

异步刷盘:能够充分利用OS的PageCache的优势,只要消息写入PageCache即可将成功的ACK返回给Producer端.
		消息刷盘采用后台异步线程提交的方式进行,降低了读写延迟,提高了MQ的性能和吞吐量.

------------------------------------------限流-----------------------------------
问题: 在PUSH模式下如果消费速率小于生产速率,非常容易造成大量阻塞. 
解决(默认处理方式): 
A.消息堆积数量: 
如果消息消费处理队列中的消息条数超过1000条会触发消费端的流控,其具体做法是放弃本次拉取动作,
并且延迟50ms后将放入该拉取任务放入到pullRequestQueue中,每1000次流控会打印一次消费端流控日志.

B.消息堆积大小
如果处理队列中堆积的消息总内存大小超过100M,同样触发一次流控.

------------------------------------------Broker可用性-----------------------------------
由于消息分布在各个Broker上,一旦某个Broker宕机,则该Broker上的消息读写都会受到影响.
	
所以RocketMQ提供了Master/Slave的结构,Salve定时从Master同步数据,如果Master宕机,则Slave提供消费服务,但是不能写入消息,此过程对应用透明,由RocketMQ内部解决.

思考1一旦某个broker master宕机,生产者和消费者多久才能发现?

受限于Rocketmq的网络连接机制,默认情况下最多需要30秒,因为消费者每隔30秒从nameserver获取所有topic的最新队列情况,这意味着某个broker如果宕机,客户端最多要30秒才能感知.

思考2 master恢复恢复后,消息能否恢复.
消费者得到Master宕机通知后,转向Slave消费,但是Slave不能保证Master的消息100%都同步过来了,因此会有少量的消息丢失.但是消息最终不会丢的,一旦Master恢复,未同步过去的消息会被消费掉.

Topic路由注册与剔除流程:
Broker每30s向NameServer发送心跳包,心跳包中包含主题的路由信息(主题的读写队列数、操作权限等),
NameServer会通过HashMap更新Topic的路由信息,并记录最后一次收到Broker的时间戳.

NameServer以每10s的频率清除已宕机的Broker,NameServer认为Broker宕机的依据是如果当前系统时间戳
减去最后一次收到Broker心跳包的时间戳大于120s.

消息生产者以每30s的频率去拉取主题的路由信息,即消息生产者并不会立即感知Broker服务器的新增与删除.

------------------------------------------消息可用性-----------------------------------
mq如何保证可靠消息的? 刷盘机制改下(异步刷改成同步)、主从同步机制改下(同步双写)、消费时筛选下过期消息.
本地消息表:  https://houbb.github.io/2018/09/02/sql-distribute-transaction-mq
重复消息如何处理?
记录消费记录就行了,如果记录到缓存里记得设置过期时间(下一个凌晨4点就行,mq会在那时清过期数据).

------------------------------------------生产、消费分组概念-----------------------------------
相同的分组名称表明生产者实例在概念上归属于同一分组.这对事务消息十分重要,如果原始生产者在事务之后崩溃,
那么broker可以联系同一生产者分组的不同生产者实例来提交或回滚事务.

消费组用于支持'广播模式'和'集群模式'.

--
消费队列负载算法与重平衡机制:
前言: 
在MQ领域有一个不成文的约定: 同一个消费者同一时间可以分配多个队列,但一个队列同一时间只会分配给一个消费者.

常见分配机制:
AllocateMessageQueueAveragely: 平均分配到所有消费者(一次性分配avg个),有冗余时按顺序分配给消费者.
AllocateMessageQueueAveragelyByCircle: 一个一个分配.

消费队列重平衡机制: 用于运行时新增节点
RocketMQ客户端中会每隔20s去查询当前topic的所有队列、消费者的个数,运用队列负载算法进行重新分配,
然后与上一次的分配结果进行对比,如果发生了变化,则进行队列重新分配;

------------------------------------------实用点-----------------------------------
Consumer配置: 
`consumeThreadMin、consumeThreadMax`可以提高消费速率,但需要考虑业务属于IO还是CPU密集型任务(一般是IO).
`consumeMessageBatchMaxSize`表示批量消费.

其它配置参考: https://zhuanlan.zhihu.com/p/27397055

------------------------------------------PushConsumer和PullConsumer区别-----------------------------------
参考: https://www.cnblogs.com/Eternally-dream/p/9956622.html(简单,了解个大概大概大概)
	  、https://blog.csdn.net/prestigeding/article/details/79350041(代码)
Pull和Push在于一个是手动调pull拿消息,一个是用listener拿消息. Push让用户感觉到这服务器推送的消息,实际上是自己通过轮询
不停的去从Broker里'问'数据.

ConsumeWhere的坑: https://blog.csdn.net/prestigeding/article/details/96576932
------------------------------------------namespace是干啥的-----------------------------------
给GROUP加统一前缀的,GroupName实际上等于Namespace+'%'+GroupName: NamespaceUtil#wrapNamespace

------------------------------------------事务-----------------------------------
RocketMQ事务消息设计则主要是为了解决producer端的消息发送与本地事务执行的原子性问题,
RocketMQ的设计中broker与producer端的双向通信能力,使得broker天生可以作为一个事务协调者存在.

------------------------------------------HA-----------------------------------
Raft协议实现自动选举新的Master: https://www.infoq.cn/article/7xeJrpDZBa9v*GDZOFS6 

master和slave都可以提供读服务,但是只有master允许做写入操作,slave仅从master同步数据并
不断上报自己的同步进度(slave自己的物理max offset).

当同步策略为`SYNC_MASTER`时表示双写,这个双写含义是只要有一个Slave复制成功并成功应答即算成功.
并且并不代表已经持久化到了磁盘,只能保证肯定到了PageCache,因为这个是由Slave自己的刷盘配置决定的.

------------------------------------------注意事项-----------------------------------
并发消费模型中,消息消费失败默认会重试16次,每一次的间隔时间不一样;而顺序消费,如果一条消息消费失败,
则会一直消费,直到消费成功.故在顺序消费的使用过程中,应用程序需要区分系统异常、业务异常,如果是不符合
业务规则导致的异常,则重试多少次都无法消费成功,这个时候一定要告警机制,及时进行人为干预,否则消费会积压.

--
下面的参考: https://zhuanlan.zhihu.com/p/25265380

PushConsumer的配置`ConsumeFromWhere`并不能直接配置这次从哪里开始消费,它是在当Broker没有存消费进度
时才生效的(试了,确实).

在一些场景消费消息时很有必要做幂等: RocketMQ是以consumer group+queue为单位是管理消费进度的,以一个
consumer offset标记这个这个消费组在这条queue上的消费进度.如果某已存在的消费组出现了新消费实例的时候,
依靠这个组的消费进度,就可以判断第一次是从哪里开始拉取的. 每次消息成功后,本地的消费进度会被更新,
然后由定时器定时同步到broker,以此持久化消费进度. 但是每次记录消费进度的时候,只会把一批消息中最小的
offset值为消费进度值. 这种方式和传统的一条message单独ack的方式有本质的区别.性能上提升的同时,会带来
一个潜在的重复问题--由于消费进度只是记录了一个下标,就可能出现拉取了100条消息如2101-2200的消息,后面
99条都消费结束了,只有2101消费一直没有结束的情况. DefaultMQPushConsumer有个配置
`consumeConcurrentlyMaxSpan=2000`,当RocketMQ发现本地缓存的消息的最大值-最小值差距大于这个值的时候,
会触发流控.  还有个机制就是超时设置: `consumeTimeout`.
--

--
下面的参考: https://zhuanlan.zhihu.com/p/163248992
Consumer记录offset时实际上是根据消费组来区分的,它物理记录的格式为:
```
{
	"offsetTable":{
		"TopicTest@pullConsumerGroupTest":{0:1578,1:1578,2:1578,3:1578
		}
	}
}
```
key组成格式为`Topic@ConsumerGroup`.

所以说如果你的CONSUME_FROM_LAST不生效,请先问问自己是否属于以下两个情况:
1. 这个消费者组本来就监听这个Topic,你修改ConsumeFromWhere策略发布.对不起,这时候这个策略对于这个topic是不生效的.

2. 这个消费者组本来就监听过这个Topic,但是由于后面服务发版的历史中,已经不监听了.但突然有一天,你发现又需要重新监听了,
   这时候ConsumeFromWhere也是不生效的.原因就是这个消费进度一直都被broker记住了.
--

------------------------------------------MessageFilter-----------------------------------
自定义消息过滤,用于过滤消息的,只作用与Broker所在的机器. 实际上过滤消息功能也可以在消费端消费消息的
时候过滤. 它的作用在于用Broker的CPU资源换取网卡资源,这通常是非常值得的.

